<?xml version="1.0" encoding="utf-8"?>
<!-- Created by Leo: https://leo-editor.github.io/leo-editor/leo_toc.html -->
<leo_file xmlns:leo="https://leo-editor.github.io/leo-editor/namespaces/leo-python-editor/1.1" >
<leo_header file_format="2"/>
<globals/>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ekr.20240927151701.1" descendentVnodeUnknownAttributes="7d7100285803000000302e3071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a73735805000000302e302e3771067d71075808000000616e6e6f7461746571087d71092858080000007072696f72697479710a4d0f27580a00000070726973657464617465710b580a000000323032312d30332d3330710c75735803000000302e31710d7d710e580b0000005f5f626f6f6b6d61726b73710f7d7110580700000069735f6475706571114930300a7373752e"><vh>Startup</vh>
<v t="ekr.20240927151701.9" descendentVnodeUnknownAttributes="7d71002858010000003071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a73735803000000302e3771067d71075808000000616e6e6f7461746571087d71092858080000007072696f72697479710a4d0f27580a00000070726973657464617465710b580a000000323032312d30332d3330710c7573752e"><vh>@settings</vh>
<v t="ekr.20240927151701.44"><vh>@bool allow-text-zoom = True</vh></v>
<v t="ekr.20240927151701.45"><vh>@bool check-python-code-on-write = False</vh></v>
<v t="ekr.20240927151701.46"><vh>@bool use-german-keyboard = False</vh></v>
<v t="ekr.20240927151701.47"><vh>@bool use-mouse-expand-gestures = False</vh></v>
<v t="ekr.20240927151701.48"><vh>@data exec-script-commands</vh></v>
<v t="ekr.20240927151701.49"><vh>@data exec-script-patterns</vh></v>
<v t="ekr.20240927151701.50"><vh>@data history-list</vh></v>
<v t="ekr.20240927151701.170" descendentVnodeUnknownAttributes="7d710058010000003071017d71025808000000616e6e6f7461746571037d71042858080000007072696f7269747971054d0f27580a000000707269736574646174657106580a000000323032312d30332d333071077573732e"><vh>@enabled-plugins</vh></v>
<v t="ekr.20240927151701.51"><vh>@string qt-layout-name = legacy</vh></v>
<v t="ekr.20240927151701.92"><vh>Appearance settings</vh>
<v t="ekr.20240927151701.93"><vh>@bool log-pane-wraps = False</vh></v>
<v t="ekr.20240927151701.94"><vh>@bool recent-files-group-always = True</vh></v>
<v t="ekr.20240927151701.95"><vh>@bool show-iconbar = True</vh></v>
<v t="ekr.20240927151701.96"><vh>@bool show-tips = False</vh></v>
<v t="ekr.20240927151701.97"><vh>@bool stayInTreeAfterSelect = True</vh></v>
<v t="ekr.20240927151701.98"><vh>@bool use-chapter-tabs = False</vh></v>
<v t="ekr.20240927151701.99"><vh>@bool use-chapters = False</vh></v>
<v t="ekr.20240927151701.100"><vh>@bool use-gutter = False</vh></v>
<v t="ekr.20240927151701.101"><vh>@int qweb-view-font-size = 30</vh></v>
<v t="ekr.20240927151701.102"><vh>@string initial-split-orientation = v</vh></v>
</v>
<v t="ekr.20240927151701.103"><vh>Coloring settings</vh>
<v t="ekr.20240927151701.104"><vh>@bool color-doc-parts-as-rest = True</vh></v>
<v t="ekr.20240927151701.105"><vh>@bool use-pygments = False</vh></v>
<v t="ekr.20240927151701.106"><vh>@bool use-pygments-styles = False</vh></v>
<v t="ekr.20240927151701.107"><vh>@color head-bg = @mistyrose2</vh></v>
<v t="ekr.20240927151701.108"><vh>@string pygments-style-name = leonine</vh></v>
<v t="ekr.20240927151701.109"><vh>@string target-language = rust</vh></v>
</v>
<v t="ekr.20240927151701.110"><vh>Command settings</vh>
<v t="ekr.20240927151701.111"><vh>@bool create-at-persistence-nodes-automatically = False</vh></v>
<v t="ekr.20240927151701.112"><vh>@bool enable-persistence = False</vh></v>
<v t="ekr.20240927151701.113"><vh>@bool make-node-conflicts-node = True</vh></v>
<v t="ekr.20240927151701.184"><vh>@bool qt-use-scintilla = False</vh></v>
<v t="ekr.20240927151701.114"><vh>@bool run-pyflakes-on-write = False</vh></v>
<v t="ekr.20240927151701.126"><vh>@bool tree-declutter = False</vh></v>
<v t="ekr.20240927151701.115"><vh>@bool use-jedi = False</vh></v>
<v t="ekr.20240927151701.116"><vh>@bool use-qcompleter = False</vh></v>
<v t="ekr.20240927151701.202"><vh>@bool vim-mode = False</vh></v>
<v t="ekr.20240927151701.117"><vh>@bool warn-about-redefined-shortcuts = True</vh></v>
<v t="ekr.20240927151701.118"><vh>@int auto-justify = 80</vh></v>
<v t="ekr.20240927151701.119"><vh>rst3 path options</vh>
<v t="ekr.20240927151701.120"><vh>@string rst3-write-intermediate-extension = .txt</vh></v>
<v t="ekr.20240927151701.121"><vh>@string rst3-default-path = None</vh></v>
<v t="ekr.20240927151701.122"><vh>@string rst3-stylesheet-name = default.css</vh></v>
<v t="ekr.20240927151701.123"><vh>@string rst3-stylesheet-path = None</vh></v>
<v t="ekr.20240927151701.124"><vh>@string rst3-publish-argv-for-missing-stylesheets = None</vh></v>
</v>
</v>
<v t="ekr.20240927151701.144"><vh>File settings</vh>
<v t="ekr.20240927151701.145"><vh>@bool open-with-clean-filenames = True</vh></v>
<v t="ekr.20240927151701.146"><vh>@bool check-for-changed-external-files = True</vh></v>
<v t="ekr.20240927151701.147"><vh>@bool open-with-save-on-update = False</vh></v>
<v t="ekr.20240927151701.148"><vh>@bool open-with-uses-derived-file-extensions = True</vh></v>
</v>
<v t="ekr.20240927151701.149"><vh>Find settings</vh>
<v t="ekr.20240927151701.150"><vh>@bool auto-scroll-find-tab = False</vh></v>
<v t="ekr.20240927151701.151"><vh>@bool close-find-dialog-after-search = False</vh></v>
<v t="ekr.20240927151701.152"><vh>@bool find-ignore-duplicates = False</vh></v>
<v t="ekr.20240927151701.153"><vh>@bool minibuffer-find-mode = True</vh></v>
<v t="ekr.20240927151701.154"><vh>@bool use-find-dialog = False</vh></v>
</v>
<v t="ekr.20240927151701.155"><vh>Importer settings</vh>
<v t="ekr.20240927151701.156"><vh>@data import-html-tags</vh></v>
<v t="ekr.20240927151701.157"><vh>@data import-xml-tags</vh></v>
</v>
<v t="ekr.20240927153018.1"><vh>Scripts</vh>
<v t="ekr.20240927151701.229"><vh> Recursive import script</vh>
<v t="ekr.20240927151701.230"><vh>&lt;&lt; rust dir_list &gt;&gt;</vh></v>
</v>
</v>
<v t="ekr.20240927151701.190"><vh>Syntax coloring settings</vh>
<v t="ekr.20240927151701.191"><vh>@@color rest.keyword2 = red</vh></v>
<v t="ekr.20240927151701.192"><vh>@@color rest.keyword4 = blue</vh></v>
<v t="ekr.20240927151701.193"><vh>@@color rest.leokeyword = green</vh></v>
<v t="ekr.20240927151701.194"><vh>@color forth.keyword3 = black</vh></v>
<v t="ekr.20240927151701.195"><vh>@color python.name = @solarized-yellow</vh></v>
<v t="ekr.20240927151701.196"><vh>@font rest.comment1</vh></v>
</v>
<v t="ekr.20240927151701.176"><vh>VR settings</vh>
<v t="ekr.20240927151701.177"><vh>@bool view-rendered-auto-create = False</vh></v>
<v t="ekr.20240927151701.178"><vh>@bool view-rendered-auto-hide = False</vh></v>
<v t="ekr.20240927151701.179"><vh>@string view-rendered-default-kind = rst</vh></v>
</v>
</v>
<v t="ekr.20240927151701.203" descendentVnodeUnknownAttributes="7d710058010000003071017d7102580b0000005f5f626f6f6b6d61726b7371037d7104580700000069735f6475706571054930300a7373732e"><vh>Buttons &amp; commands</vh>
<v t="ekr.20240927151701.206"><vh>@button backup</vh></v>
<v t="ekr.20240928073118.1"><vh>@button cargo-fmt</vh></v>
<v t="ekr.20240927152759.1"><vh>@button cargo-run</vh></v>
<v t="ekr.20240930063740.1"><vh>@@command ga</vh></v>
<v t="ekr.20240930101156.1"><vh>@@command ga-leo</vh></v>
<v t="ekr.20240930063514.1"><vh>@@command gc</vh></v>
<v t="ekr.20240930063546.1"><vh>@command gs</vh></v>
<v t="ekr.20240930064435.1"><vh>@@command git-reset</vh></v>
<v t="ekr.20240930064622.1"><vh>@@command push</vh></v>
<v t="ekr.20240927151701.207"><vh>@@button print-gnx</vh></v>
</v>
</v>
<v t="ekr.20240927154009.1"><vh>Files</vh>
<v t="ekr.20240927151245.1"><vh>@edit Cargo.toml</vh></v>
<v t="ekr.20240927151332.1"><vh>@file src/main.rs</vh></v>
<v t="ekr.20240928161210.1"><vh>@file src/tbo.rs</vh></v>
</v>
<v t="ekr.20241001073040.1"><vh>--- Not used</vh>
<v t="ekr.20241005031511.1"><vh>COPY (Python) class InputToken</vh>
<v t="ekr.20241005031511.2"><vh>itoken.brief_dump</vh></v>
<v t="ekr.20241005031511.3"><vh>itoken.dump</vh></v>
<v t="ekr.20241005031511.4"><vh>itoken.dump_header</vh></v>
<v t="ekr.20241005031511.5"><vh>itoken.error_dump</vh></v>
<v t="ekr.20241005031511.6"><vh>itoken.show_val</vh></v>
</v>
<v t="ekr.20241003062509.1"><vh>--- old Rust code</vh>
<v t="ekr.20241003055233.1"><vh>beautify_one_file: 'static</vh></v>
<v t="ekr.20241001093308.2"><vh>fn tokenize</vh>
<v t="ekr.20241001093308.3"><vh>&lt;&lt; tokenize: define contents &gt;&gt;</vh></v>
</v>
<v t="ekr.20240929032636.1"><vh>function: entry &amp; helpers</vh>
<v t="ekr.20240930100625.1"><vh>&lt;&lt; 1: read &gt;&gt;</vh></v>
<v t="ekr.20240930100707.1"><vh>&lt;&lt; 2: make input_list &gt;&gt;</vh></v>
<v t="ekr.20240930100553.1"><vh>&lt;&lt; 3: print stats &gt;&gt;</vh></v>
<v t="ekr.20240929033044.1"><vh>function: add_input_token</vh></v>
<v t="ekr.20240929032710.1"><vh>function: fmt_ms</vh></v>
<v t="ekr.20240929024648.113"><vh>function: make_input_list (works)</vh></v>
<v t="ekr.20240930084648.1"><vh>function: read</vh></v>
</v>
<v t="ekr.20240930085546.1"><vh>function: lex_contents</vh></v>
<v t="ekr.20240929031635.1"><vh>function: scan_input_list</vh></v>
<v t="ekr.20241001071914.1"><vh>function: test_loop</vh></v>
<v t="ekr.20241003063446.121"><vh>LB::string_to_static_str</vh></v>
<v t="ekr.20241002164044.1"><vh>make_input_list: Calculate class name w/o match</vh></v>
<v t="ekr.20240929074941.1"><vh>Stats::update_times</vh></v>
</v>
<v t="ekr.20241003084853.1"><vh>--- new code: doesn't work</vh>
<v t="ekr.20241003064504.1"><vh>functions to be added</vh>
<v t="ekr.20241003063446.114"><vh>fn: enabled</vh></v>
<v t="ekr.20241003063446.115"><vh>fn: get_args</vh></v>
<v t="ekr.20241003063446.118"><vh>fn: show_args</vh></v>
<v t="ekr.20241003063446.119"><vh>fn: show_help</vh></v>
<v t="ekr.20241003063446.120"><vh>fn: show_output_list</vh></v>
</v>
<v t="ekr.20241003084902.1"><vh>COPY: pub fn entry </vh></v>
<v t="ekr.20241003064425.1"><vh>Beautifier struct</vh></v>
<v t="ekr.20241003063446.6"><vh>&lt;&lt; fn: beautify: init vars &gt;&gt; (to do)</vh></v>
<v t="ekr.20241003063446.1"><vh>LeoBeautifier functions</vh>
<v t="ekr.20241003063446.3"><vh>fn: add_input_token</vh></v>
<v t="ekr.20241003063446.4"><vh>fn: add_output_string</vh></v>
<v t="ekr.20241003063446.5"><vh>fn: beautify</vh>
<v t="ekr.20241003063446.7"><vh>&lt;&lt; LB: beautify: dispatch on input_token.kind &gt;&gt;</vh></v>
</v>
<v t="ekr.20241003063446.8"><vh>fn: beautify_all_files</vh></v>
<v t="ekr.20241003063446.9"><vh>fn: beautify_one_file</vh></v>
<v t="ekr.20241003063446.116"><vh>fn: make_input_list</vh>
<v t="ekr.20241003063446.117"><vh>&lt;&lt; Calculate class_name using match token &gt;&gt;</vh></v>
</v>
<v t="ekr.20241003063446.10"><vh>fn: do_*</vh>
<v t="ekr.20241003063446.11"><vh>tbo.do_ws</vh></v>
<v t="ekr.20241003063446.12"><vh>LB:Handlers with values</vh>
<v t="ekr.20241003063446.13"><vh>fn: do_Comment</vh></v>
<v t="ekr.20241003063446.14"><vh>fn: do_Complex</vh></v>
<v t="ekr.20241003063446.15"><vh>fn: do_Float</vh></v>
<v t="ekr.20241003063446.16"><vh>fn: do_Int</vh></v>
<v t="ekr.20241003063446.17"><vh>fn: do_Name</vh></v>
<v t="ekr.20241003063446.18"><vh>fn: do_String</vh></v>
</v>
<v t="ekr.20241003063446.19"><vh>LB:Handlers using lws</vh>
<v t="ekr.20241003063446.20"><vh>fn: do_Dedent</vh></v>
<v t="ekr.20241003063446.21"><vh>fn: do_Indent</vh></v>
<v t="ekr.20241003063446.22"><vh>fn: do_Newline</vh></v>
<v t="ekr.20241003063446.23"><vh>fn: do_NonLogicalNewline</vh></v>
</v>
<v t="ekr.20241003063446.24"><vh>LB:Handlers w/o values</vh>
<v t="ekr.20241003063446.25"><vh>fn: do_Amper</vh></v>
<v t="ekr.20241003063446.26"><vh>fn: do_AmperEqual</vh></v>
<v t="ekr.20241003063446.27"><vh>fn: do_And</vh></v>
<v t="ekr.20241003063446.28"><vh>fn: do_As</vh></v>
<v t="ekr.20241003063446.29"><vh>fn: do_Assert</vh></v>
<v t="ekr.20241003063446.30"><vh>fn: do_Async</vh></v>
<v t="ekr.20241003063446.31"><vh>fn: do_At</vh></v>
<v t="ekr.20241003063446.32"><vh>fn: do_AtEqual</vh></v>
<v t="ekr.20241003063446.33"><vh>fn: do_Await</vh></v>
<v t="ekr.20241003063446.34"><vh>fn: do_Break</vh></v>
<v t="ekr.20241003063446.35"><vh>fn: do_Case</vh></v>
<v t="ekr.20241003063446.36"><vh>fn: do_CircumFlex</vh></v>
<v t="ekr.20241003063446.37"><vh>fn: do_CircumflexEqual</vh></v>
<v t="ekr.20241003063446.38"><vh>fn: do_Class</vh></v>
<v t="ekr.20241003063446.39"><vh>fn: do_Colon</vh></v>
<v t="ekr.20241003063446.40"><vh>fn: do_ColonEqual</vh></v>
<v t="ekr.20241003063446.41"><vh>fn: do_Comma</vh></v>
<v t="ekr.20241003063446.42"><vh>fn: do_Continue</vh></v>
<v t="ekr.20241003063446.43"><vh>fn: do_Def</vh></v>
<v t="ekr.20241003063446.44"><vh>fn: do_Del</vh></v>
<v t="ekr.20241003063446.45"><vh>fn: do_Dot</vh></v>
<v t="ekr.20241003063446.46"><vh>fn: do_DoubleSlash</vh></v>
<v t="ekr.20241003063446.47"><vh>fn: do_DoubleSlashEqual</vh></v>
<v t="ekr.20241003063446.48"><vh>fn: do_DoubleStar</vh></v>
<v t="ekr.20241003063446.49"><vh>fn: do_DoubleStarEqual</vh></v>
<v t="ekr.20241003063446.50"><vh>fn: do_Elif</vh></v>
<v t="ekr.20241003063446.51"><vh>fn: do_Ellipsis</vh></v>
<v t="ekr.20241003063446.52"><vh>fn: do_Else</vh></v>
<v t="ekr.20241003063446.53"><vh>fn: do_EndOfFile</vh></v>
<v t="ekr.20241003063446.54"><vh>fn: do_EqEqual</vh></v>
<v t="ekr.20241003063446.55"><vh>fn: do_Equal</vh></v>
<v t="ekr.20241003063446.56"><vh>fn: do_Except</vh></v>
<v t="ekr.20241003063446.57"><vh>fn: do_False</vh></v>
<v t="ekr.20241003063446.58"><vh>fn: do_Finally</vh></v>
<v t="ekr.20241003063446.59"><vh>fn: do_For</vh></v>
<v t="ekr.20241003063446.60"><vh>fn: do_From</vh></v>
<v t="ekr.20241003063446.61"><vh>fn: do_Global</vh></v>
<v t="ekr.20241003063446.62"><vh>fn: do_Greater</vh></v>
<v t="ekr.20241003063446.63"><vh>fn: do_GreaterEqual</vh></v>
<v t="ekr.20241003063446.64"><vh>fn: do_If</vh></v>
<v t="ekr.20241003063446.65"><vh>fn: do_Import</vh></v>
<v t="ekr.20241003063446.66"><vh>fn: do_In</vh></v>
<v t="ekr.20241003063446.67"><vh>fn: do_Is</vh></v>
<v t="ekr.20241003063446.68"><vh>fn: do_Lambda</vh></v>
<v t="ekr.20241003063446.69"><vh>fn: do_Lbrace</vh></v>
<v t="ekr.20241003063446.70"><vh>fn: do_LeftShift</vh></v>
<v t="ekr.20241003063446.71"><vh>fn: do_LeftShiftEqual</vh></v>
<v t="ekr.20241003063446.72"><vh>fn: do_Less</vh></v>
<v t="ekr.20241003063446.73"><vh>fn: do_LessEqual</vh></v>
<v t="ekr.20241003063446.74"><vh>fn: do_Lpar</vh></v>
<v t="ekr.20241003063446.75"><vh>fn: do_Lsqb</vh></v>
<v t="ekr.20241003063446.76"><vh>fn: do_Match</vh></v>
<v t="ekr.20241003063446.77"><vh>fn: do_Minus</vh></v>
<v t="ekr.20241003063446.78"><vh>fn: do_MinusEqual</vh></v>
<v t="ekr.20241003063446.79"><vh>fn: do_None</vh></v>
<v t="ekr.20241003063446.80"><vh>fn: do_Nonlocal</vh></v>
<v t="ekr.20241003063446.81"><vh>fn: do_Not</vh></v>
<v t="ekr.20241003063446.82"><vh>fn: do_NotEqual</vh></v>
<v t="ekr.20241003063446.83"><vh>fn: do_Or</vh></v>
<v t="ekr.20241003063446.84"><vh>fn: do_Pass</vh></v>
<v t="ekr.20241003063446.85"><vh>fn: do_Percent</vh></v>
<v t="ekr.20241003063446.86"><vh>fn: do_PercentEqual</vh></v>
<v t="ekr.20241003063446.87"><vh>fn: do_Plus</vh></v>
<v t="ekr.20241003063446.88"><vh>fn: do_PlusEqual</vh></v>
<v t="ekr.20241003063446.89"><vh>fn: do_Raise</vh></v>
<v t="ekr.20241003063446.90"><vh>fn: do_Rarrow</vh></v>
<v t="ekr.20241003063446.91"><vh>fn: do_Rbrace</vh></v>
<v t="ekr.20241003063446.92"><vh>fn: do_Return</vh></v>
<v t="ekr.20241003063446.93"><vh>fn: do_RightShift</vh></v>
<v t="ekr.20241003063446.94"><vh>fn: do_RightShiftEqual</vh></v>
<v t="ekr.20241003063446.95"><vh>fn: do_Rpar</vh></v>
<v t="ekr.20241003063446.96"><vh>fn: do_Rsqb</vh></v>
<v t="ekr.20241003063446.97"><vh>fn: do_Semi</vh></v>
<v t="ekr.20241003063446.98"><vh>fn: do_Slash</vh></v>
<v t="ekr.20241003063446.99"><vh>fn: do_SlashEqual</vh></v>
<v t="ekr.20241003063446.100"><vh>fn: do_Star</vh></v>
<v t="ekr.20241003063446.101"><vh>fn: do_StarEqual</vh></v>
<v t="ekr.20241003063446.102"><vh>fn: do_StartExpression</vh></v>
<v t="ekr.20241003063446.103"><vh>fn: do_StartInteractive</vh></v>
<v t="ekr.20241003063446.104"><vh>fn: do_StarModule</vh></v>
<v t="ekr.20241003063446.105"><vh>fn: do_Tilde</vh></v>
<v t="ekr.20241003063446.106"><vh>fn: do_True</vh></v>
<v t="ekr.20241003063446.107"><vh>fn: do_Try</vh></v>
<v t="ekr.20241003063446.108"><vh>fn: do_Type</vh></v>
<v t="ekr.20241003063446.109"><vh>fn: do_Vbar</vh></v>
<v t="ekr.20241003063446.110"><vh>fn: do_VbarEqual</vh></v>
<v t="ekr.20241003063446.111"><vh>fn: do_While</vh></v>
<v t="ekr.20241003063446.112"><vh>fn: do_With</vh></v>
<v t="ekr.20241003063446.113"><vh>fn: do_Yield</vh></v>
</v>
</v>
</v>
</v>
<v t="ekr.20241004084640.1"><vh>--- unused LB methods</vh>
<v t="ekr.20240929074037.3"><vh>LB::add_input_token (no longer used)</vh></v>
<v t="ekr.20240929074037.117"><vh>LB::show_output_list (no longer used)</vh></v>
</v>
<v t="ekr.20241004093044.1"><vh>--- unused fmt::Debug for InputTok</vh></v>
</v>
<v t="ekr.20240927154016.1"><vh>Notes</vh>
<v t="ekr.20240929084852.1"><vh>Ownership and mutation</vh></v>
<v t="ekr.20241001055017.1"><vh>Traits</vh></v>
<v t="ekr.20241001060848.1"><vh>Lifetimes (to do)</vh></v>
<v t="ekr.20241002054443.1"><vh>Errors in LB:beautify</vh></v>
<v t="ekr.20240928185643.1"><vh>Stats</vh></v>
</v>
<v t="ekr.20240927154323.1"><vh>** To do</vh></v>
<v t="ekr.20241001104914.1"><vh>--- classes</vh>
<v t="ekr.20241004095931.1"><vh>class AnnotatedInputTok</vh></v>
<v t="ekr.20241004110721.1"><vh>class Annotator</vh>
<v t="ekr.20241004153742.1"><vh>Annotator.new</vh></v>
<v t="ekr.20241005091217.1"><vh>Annotator.is_python_keyword (to do)</vh></v>
<v t="ekr.20241005092549.1"><vh>Annotator.is_unary_op_with_prev (to do)</vh></v>
<v t="ekr.20241004153802.1"><vh>Annotator.pre_scan &amp; helpers</vh>
<v t="ekr.20241004154345.2"><vh>&lt;&lt; pre-scan newline tokens &gt;&gt;</vh></v>
<v t="ekr.20241004154345.3"><vh>&lt;&lt; pre-scan op tokens &gt;&gt;</vh></v>
<v t="ekr.20241004154345.4"><vh>&lt;&lt; pre-scan name tokens &gt;&gt;</vh></v>
<v t="ekr.20241004154345.5"><vh>Annotator.finish_arg</vh></v>
<v t="ekr.20241004154345.6"><vh>Annotator.finish_slice</vh></v>
<v t="ekr.20241004154345.7"><vh>Annotator.finish_dict</vh></v>
<v t="ekr.20241004163018.1"><vh>Annotator.set_context</vh></v>
</v>
</v>
<v t="ekr.20240929024648.120"><vh>class InputTok</vh></v>
<v t="ekr.20240929074037.1"><vh>class LeoBeautifier</vh>
<v t="ekr.20240929074037.114"><vh> LB::new</vh></v>
<v t="ekr.20240929074037.2"><vh>LB::add_output_string</vh></v>
<v t="ekr.20241004095735.1"><vh>LB::annotate_tokens (**finish)</vh></v>
<v t="ekr.20240929074037.113"><vh>LB::beautify</vh>
<v t="ekr.20241002062655.1"><vh>&lt;&lt; LB: beautify: dispatch on input_token.kind &gt;&gt;</vh></v>
</v>
<v t="ekr.20240929074037.4"><vh>LB::beautify_all_files</vh></v>
<v t="ekr.20240929074037.5"><vh>LB::beautify_one_file</vh></v>
<v t="ekr.20240929074037.7"><vh>LB::do_*</vh>
<v t="ekr.20241002071143.1"><vh>tbo.do_ws</vh></v>
<v t="ekr.20240929074037.8"><vh>LB:Handlers with values</vh>
<v t="ekr.20240929074037.9"><vh>LB::do_Comment</vh></v>
<v t="ekr.20240929074037.10"><vh>LB::do_Complex</vh></v>
<v t="ekr.20240929074037.11"><vh>LB::do_Float</vh></v>
<v t="ekr.20240929074037.12"><vh>LB::do_Int</vh></v>
<v t="ekr.20240929074037.13"><vh>LB::do_Name</vh></v>
<v t="ekr.20240929074037.14"><vh>LB::do_String</vh></v>
</v>
<v t="ekr.20240929074037.15"><vh>LB:Handlers using lws</vh>
<v t="ekr.20240929074037.16"><vh>LB::do_Dedent</vh></v>
<v t="ekr.20240929074037.17"><vh>LB::do_Indent</vh></v>
<v t="ekr.20240929074037.18"><vh>LB::do_Newline</vh></v>
<v t="ekr.20240929074037.19"><vh>LB::do_NonLogicalNewline</vh></v>
</v>
<v t="ekr.20240929074037.20"><vh>LB:Handlers w/o values</vh>
<v t="ekr.20240929074037.21"><vh>LB::do_Amper</vh></v>
<v t="ekr.20240929074037.22"><vh>LB::do_AmperEqual</vh></v>
<v t="ekr.20240929074037.23"><vh>LB::do_And</vh></v>
<v t="ekr.20240929074037.24"><vh>LB::do_As</vh></v>
<v t="ekr.20240929074037.25"><vh>LB::do_Assert</vh></v>
<v t="ekr.20240929074037.26"><vh>LB::do_Async</vh></v>
<v t="ekr.20240929074037.27"><vh>LB::do_At</vh></v>
<v t="ekr.20240929074037.28"><vh>LB::do_AtEqual</vh></v>
<v t="ekr.20240929074037.29"><vh>LB::do_Await</vh></v>
<v t="ekr.20240929074037.30"><vh>LB::do_Break</vh></v>
<v t="ekr.20240929074037.31"><vh>LB::do_Case</vh></v>
<v t="ekr.20240929074037.32"><vh>LB::do_CircumFlex</vh></v>
<v t="ekr.20240929074037.33"><vh>LB::do_CircumflexEqual</vh></v>
<v t="ekr.20240929074037.34"><vh>LB::do_Class</vh></v>
<v t="ekr.20240929074037.35"><vh>LB::do_Colon</vh></v>
<v t="ekr.20240929074037.36"><vh>LB::do_ColonEqual</vh></v>
<v t="ekr.20240929074037.37"><vh>LB::do_Comma</vh></v>
<v t="ekr.20240929074037.38"><vh>LB::do_Continue</vh></v>
<v t="ekr.20240929074037.39"><vh>LB::do_Def</vh></v>
<v t="ekr.20240929074037.40"><vh>LB::do_Del</vh></v>
<v t="ekr.20240929074037.41"><vh>LB::do_Dot</vh></v>
<v t="ekr.20240929074037.42"><vh>LB::do_DoubleSlash</vh></v>
<v t="ekr.20240929074037.43"><vh>LB::do_DoubleSlashEqual</vh></v>
<v t="ekr.20240929074037.44"><vh>LB::do_DoubleStar</vh></v>
<v t="ekr.20240929074037.45"><vh>LB::do_DoubleStarEqual</vh></v>
<v t="ekr.20240929074037.46"><vh>LB::do_Elif</vh></v>
<v t="ekr.20240929074037.47"><vh>LB::do_Ellipsis</vh></v>
<v t="ekr.20240929074037.48"><vh>LB::do_Else</vh></v>
<v t="ekr.20240929074037.49"><vh>LB::do_EndOfFile</vh></v>
<v t="ekr.20240929074037.50"><vh>LB::do_EqEqual</vh></v>
<v t="ekr.20240929074037.51"><vh>LB::do_Equal</vh></v>
<v t="ekr.20240929074037.52"><vh>LB::do_Except</vh></v>
<v t="ekr.20240929074037.53"><vh>LB::do_False</vh></v>
<v t="ekr.20240929074037.54"><vh>LB::do_Finally</vh></v>
<v t="ekr.20240929074037.55"><vh>LB::do_For</vh></v>
<v t="ekr.20240929074037.56"><vh>LB::do_From</vh></v>
<v t="ekr.20240929074037.57"><vh>LB::do_Global</vh></v>
<v t="ekr.20240929074037.58"><vh>LB::do_Greater</vh></v>
<v t="ekr.20240929074037.59"><vh>LB::do_GreaterEqual</vh></v>
<v t="ekr.20240929074037.60"><vh>LB::do_If</vh></v>
<v t="ekr.20240929074037.61"><vh>LB::do_Import</vh></v>
<v t="ekr.20240929074037.62"><vh>LB::do_In</vh></v>
<v t="ekr.20240929074037.63"><vh>LB::do_Is</vh></v>
<v t="ekr.20240929074037.64"><vh>LB::do_Lambda</vh></v>
<v t="ekr.20240929074037.65"><vh>LB::do_Lbrace</vh></v>
<v t="ekr.20240929074037.66"><vh>LB::do_LeftShift</vh></v>
<v t="ekr.20240929074037.67"><vh>LB::do_LeftShiftEqual</vh></v>
<v t="ekr.20240929074037.68"><vh>LB::do_Less</vh></v>
<v t="ekr.20240929074037.69"><vh>LB::do_LessEqual</vh></v>
<v t="ekr.20240929074037.70"><vh>LB::do_Lpar</vh></v>
<v t="ekr.20240929074037.71"><vh>LB::do_Lsqb</vh></v>
<v t="ekr.20240929074037.72"><vh>LB::do_Match</vh></v>
<v t="ekr.20240929074037.73"><vh>LB::do_Minus</vh></v>
<v t="ekr.20240929074037.74"><vh>LB::do_MinusEqual</vh></v>
<v t="ekr.20240929074037.75"><vh>LB::do_None</vh></v>
<v t="ekr.20240929074037.76"><vh>LB::do_Nonlocal</vh></v>
<v t="ekr.20240929074037.77"><vh>LB::do_Not</vh></v>
<v t="ekr.20240929074037.78"><vh>LB::do_NotEqual</vh></v>
<v t="ekr.20240929074037.79"><vh>LB::do_Or</vh></v>
<v t="ekr.20240929074037.80"><vh>LB::do_Pass</vh></v>
<v t="ekr.20240929074037.81"><vh>LB::do_Percent</vh></v>
<v t="ekr.20240929074037.82"><vh>LB::do_PercentEqual</vh></v>
<v t="ekr.20240929074037.83"><vh>LB::do_Plus</vh></v>
<v t="ekr.20240929074037.84"><vh>LB::do_PlusEqual</vh></v>
<v t="ekr.20240929074037.85"><vh>LB::do_Raise</vh></v>
<v t="ekr.20240929074037.86"><vh>LB::do_Rarrow</vh></v>
<v t="ekr.20240929074037.87"><vh>LB::do_Rbrace</vh></v>
<v t="ekr.20240929074037.88"><vh>LB::do_Return</vh></v>
<v t="ekr.20240929074037.89"><vh>LB::do_RightShift</vh></v>
<v t="ekr.20240929074037.90"><vh>LB::do_RightShiftEqual</vh></v>
<v t="ekr.20240929074037.91"><vh>LB::do_Rpar</vh></v>
<v t="ekr.20240929074037.92"><vh>LB::do_Rsqb</vh></v>
<v t="ekr.20240929074037.93"><vh>LB::do_Semi</vh></v>
<v t="ekr.20240929074037.94"><vh>LB::do_Slash</vh></v>
<v t="ekr.20240929074037.95"><vh>LB::do_SlashEqual</vh></v>
<v t="ekr.20240929074037.96"><vh>LB::do_Star</vh></v>
<v t="ekr.20240929074037.97"><vh>LB::do_StarEqual</vh></v>
<v t="ekr.20240929074037.98"><vh>LB::do_StartExpression</vh></v>
<v t="ekr.20240929074037.99"><vh>LB::do_StartInteractive</vh></v>
<v t="ekr.20240929074037.100"><vh>LB::do_StarModule</vh></v>
<v t="ekr.20240929074037.101"><vh>LB::do_Tilde</vh></v>
<v t="ekr.20240929074037.102"><vh>LB::do_True</vh></v>
<v t="ekr.20240929074037.103"><vh>LB::do_Try</vh></v>
<v t="ekr.20240929074037.104"><vh>LB::do_Type</vh></v>
<v t="ekr.20240929074037.105"><vh>LB::do_Vbar</vh></v>
<v t="ekr.20240929074037.106"><vh>LB::do_VbarEqual</vh></v>
<v t="ekr.20240929074037.107"><vh>LB::do_While</vh></v>
<v t="ekr.20240929074037.108"><vh>LB::do_With</vh></v>
<v t="ekr.20240929074037.109"><vh>LB::do_Yield</vh></v>
</v>
</v>
<v t="ekr.20240929074037.110"><vh>LB::enabled</vh></v>
<v t="ekr.20240929074037.111"><vh>LB::get_args</vh></v>
<v t="ekr.20240929074037.112"><vh>LB::make_input_list</vh>
<v t="ekr.20241002113506.1"><vh>&lt;&lt; Calculate class_name using match token &gt;&gt;</vh></v>
</v>
<v t="ekr.20240929074037.115"><vh>LB::show_args</vh></v>
<v t="ekr.20240929074037.116"><vh>LB::show_help</vh></v>
<v t="ekr.20241002163554.1"><vh>LB::string_to_static_str</vh></v>
</v>
<v t="ekr.20241004112826.1"><vh>class ParseState</vh>
<v t="ekr.20241004113118.1"><vh>&lt;&lt; docstring: ParseState &gt;&gt;</vh></v>
</v>
<v t="ekr.20241004165555.1"><vh>class ScanState </vh></v>
<v t="ekr.20240929074547.1"><vh>class Stats</vh>
<v t="ekr.20241001100954.1"><vh> Stats::new</vh></v>
<v t="ekr.20240929080242.1"><vh>Stats::fmt_ns</vh></v>
<v t="ekr.20240929075236.1"><vh>Stats::report</vh></v>
</v>
</v>
<v t="ekr.20241004073317.1"><vh>--- outer leveel</vh>
<v t="ekr.20240929074037.5"></v>
<v t="ekr.20240929074037.113"></v>
</v>
<v t="ekr.20241001213229.1"><vh>from tbo.beautify (finish: do not delete)</vh></v>
<v t="ekr.20241006034023.1"><vh>*** Finish LB.annotate_tokens!</vh></v>
<v t="ekr.20241004095735.1"></v>
<v t="ekr.20241004110721.1"></v>
<v t="ekr.20241004153802.1"></v>
</vnodes>
<tnodes>
<t tx="ekr.20240927151701.1"></t>
<t tx="ekr.20240927151701.100"></t>
<t tx="ekr.20240927151701.101"></t>
<t tx="ekr.20240927151701.102">vertical (v) or horizontal (h)

myLeoSettings.leo: vertical</t>
<t tx="ekr.20240927151701.103"></t>
<t tx="ekr.20240927151701.104"></t>
<t tx="ekr.20240927151701.105">@language rest
@wrap

See #3456.

</t>
<t tx="ekr.20240927151701.106"></t>
<t tx="ekr.20240927151701.107"></t>
<t tx="ekr.20240927151701.108"># leonine</t>
<t tx="ekr.20240927151701.109"></t>
<t tx="ekr.20240927151701.110"></t>
<t tx="ekr.20240927151701.111"></t>
<t tx="ekr.20240927151701.112"></t>
<t tx="ekr.20240927151701.113">True: (Recommended) Make a "Recovered Nodes" node whenever
Leo reads a file that has been changed outside of Leo.
</t>
<t tx="ekr.20240927151701.114"></t>
<t tx="ekr.20240927151701.115"></t>
<t tx="ekr.20240927151701.116"></t>
<t tx="ekr.20240927151701.117"></t>
<t tx="ekr.20240927151701.118"></t>
<t tx="ekr.20240927151701.119"></t>
<t tx="ekr.20240927151701.120"></t>
<t tx="ekr.20240927151701.121"></t>
<t tx="ekr.20240927151701.122"></t>
<t tx="ekr.20240927151701.123"></t>
<t tx="ekr.20240927151701.124"></t>
<t tx="ekr.20240927151701.126">Set to True to enable node appearance modifications
See tree-declutter-patterns
</t>
<t tx="ekr.20240927151701.144"></t>
<t tx="ekr.20240927151701.145">Only supported with the mod_tempfname.py plugin.

True: The plugin will store temporary files utilizing cleaner
file names (no unique number is appended to the node's headline text).
Unique temporary directory paths are used to insure unique files are
created by creating temporary directories reflecting each node's ancestor
nodes in the Leo outline. Note: Do not have multiple sibling nodes (nodes
having the same parent node) in Leo with the same headline text. There will
be a conflict if both are opened in an external editor at the same time.

False: The plugin will store temporary files with an appended
unique number to insure unique temporary filenames.
</t>
<t tx="ekr.20240927151701.146">True: check all @&lt;file&gt; nodes in the outline for changes in corresponding external files.</t>
<t tx="ekr.20240927151701.147"></t>
<t tx="ekr.20240927151701.148"></t>
<t tx="ekr.20240927151701.149"></t>
<t tx="ekr.20240927151701.150"></t>
<t tx="ekr.20240927151701.151"></t>
<t tx="ekr.20240927151701.152">It is *strange* to set this to True!</t>
<t tx="ekr.20240927151701.153">@language rest

To test #2041 &amp; #2094

The @bool use-find-dialog and @bool minibuffer-find-mode settings comprise
a tri-state setting, as shown in this table:
    
minibuffer-find-mode    use-find-dialog     mode: Ctrl-F puts focus in
--------------------    ---------------     --------------------------
    True                    Ignored         minibuffer
    False                   True            dialog
    False                   False           Find tab in the log pane

*All modes*

- Start the search with Ctrl-F (start-search).
- Enter the find pattern.
- (Optional) Use &lt;Tab&gt; to enter the search pattern.
- Use &lt;Enter&gt; to start the search.

*dialog and find tab modes*

- Non-functional "buttons" remind you of key bindings.

*minibuffer mode*

- Use Ctrl-G as always to leave the minibuffer.
- The Find tab is not made visible, but the status area shows the settings.</t>
<t tx="ekr.20240927151701.154">@language rest

The @bool use-find-dialog and @bool minibuffer-find-mode settings comprise
a tri-state setting, as shown in this table:
    
minibuffer-find-mode    use-find-dialog     mode: Ctrl-F puts focus in
--------------------    ---------------     --------------------------
    True                    Ignored         minibuffer
    False                   True            dialog
    False                   False           Find tab in the log pane

*All modes*

- Start the seas with Ctrl-F (start-search).
- Enter the find pattern.
- (Optional) Use &lt;Tab&gt; to enter the search pattern.
- Use &lt;Enter&gt; to start the search.

*dialog and find tab modes*

- Non-functional "buttons" remind you of key bindings.

*minibuffer mode*

- Use Ctrl-G as always to leave the minibuffer.
- The Find tab is not made visible, but the status area shows the settings.</t>
<t tx="ekr.20240927151701.155">Added on-popover to import-html-tags (for leovue)</t>
<t tx="ekr.20240927151701.156"># lowercase html tags, one per line.
# Adds ons-popover tag for LeoVue.

a
abbr
acronym
address
applet
area
b
base
basefont
bdo
big
blockquote
body
br
button
caption
center
cite
code
col
colgroup
dd
del
dfn
dir
div
dl
dt
em
fieldset
font
form
frame
frameset
head
h1
h2
h3
h4
h5
h6
hr
html
i
iframe
img
input
ins
kbd
label
legend
li
link
map
menu
meta
noframes
noscript
object
ol
ons-popover
optgroup
option
p
param
pre
q
s
samp
script
select
small
span
strike
strong
style
sub
sup
table
tbody
td
textarea
tfoot
th
thead
title
tr
tt
u
ul
var</t>
<t tx="ekr.20240927151701.157"># lowercase xml tags, one per line.

html
body
head
div
table
</t>
<t tx="ekr.20240927151701.170" annotate="7d71002858080000007072696f7269747971014d0f27580a000000707269736574646174657102580a000000323032312d30332d33307103752e"># Recommended plugins, from leoSettings.leo:

plugins_menu.py
mod_scripting.py
nav_qt.py
viewrendered.py


# contextmenu.py      # Required by the vim.py and xemacs.py plugins.
</t>
<t tx="ekr.20240927151701.176"></t>
<t tx="ekr.20240927151701.177"># True: show vr pane when opening a file.</t>
<t tx="ekr.20240927151701.178"># True: hide the vr pane for text-only renderings.</t>
<t tx="ekr.20240927151701.179"></t>
<t tx="ekr.20240927151701.184"></t>
<t tx="ekr.20240927151701.190">Only difference from myLeoSettings.leo

Note: EKRWinowsDark.leo defines comment1_font

All three @color settings work.
The @font setting does not work.
</t>
<t tx="ekr.20240927151701.191">Bold</t>
<t tx="ekr.20240927151701.192">Italics</t>
<t tx="ekr.20240927151701.193"></t>
<t tx="ekr.20240927151701.194"># bold keywords defined in forth-bold-words</t>
<t tx="ekr.20240927151701.195"></t>
<t tx="ekr.20240927151701.196"># Note: the default font size is 12.
rest_comment1_family = None
rest_comment1_size = 12pt
rest_comment1_slant = italic
rest_comment1_weight = None
</t>
<t tx="ekr.20240927151701.202"># Note: Use jj instead of escape to end insert mode.</t>
<t tx="ekr.20240927151701.203" __bookmarks="7d7100580700000069735f6475706571014930300a732e"></t>
<t tx="ekr.20240927151701.206">@language python

"""
Back up this .leo file.

os.environ['LEO_BACKUP'] must be the path to an existing (writable) directory.
"""
c.backup_helper(sub_dir='ekr-tbo-in-rust')
</t>
<t tx="ekr.20240927151701.207">@language python

print(p.gnx)</t>
<t tx="ekr.20240927151701.229">@language python
"""Recursively import all python files in a directory and clean the result."""
@tabwidth -4 # For a better match.
g.cls()
&lt;&lt; rust dir_list &gt;&gt;

dir_ = r'C:\Python\Python3.12\Lib\site-packages\coverage'
dir_ = r'C:\Python\Python3.12\Lib\site-packages\mypyc'
dir_ = r'C:\Python\Python3.12\Lib\site-packages\findimports.py'
dir_ = r'C:\Repos\ruff\crates'

c.recursiveImport(
    dir_=dir_,
    kind = '@clean', # '@auto', '@clean', '@nosent','@file',
    recursive = True,
    safe_at_file = True,
    # '.html', '.js', '.json', '.py', '.rs', '.svg', '.ts', '.tsx']
    # '.codon', '.cpp', '.cc', '.el', '.scm',
    theTypes = ['.py', 'rs'],
    verbose = False,
)
if 1:
    last = c.lastTopLevel()
    last.expand()
    if last.hasChildren():
        last.firstChild().expand()
    c.redraw(last)
print('Done')</t>
<t tx="ekr.20240927151701.230">dir_list = (
    r'C:\Repos\RustPython\common\src',
    r'C:\Repos\RustPython\compiler\codegen\src',
    r'C:\Repos\RustPython\compiler\core\src',
    r'C:\Repos\RustPython\compiler\src',
    r'C:\Repos\RustPython\compiler\codegen\src',  # compile.rs: AST to bytecode.
    r'C:\Repos\RustPython\compiler\core\src', # bytecode.rs: implements bytecodes.
    
    r'C:\Repos\RustPython\derive\src',
    r'C:\Repos\RustPython\derive-impl\src',
    r'C:\Repos\RustPython\pylib\src',
    r'C:\Repos\RustPython\src',
    r'C:\Repos\RustPython\stdlib\src',
    r'C:\Repos\RustPython\vm\src', # compiler.rs.
    r'C:\Repos\RustPython\vm\src\stdlib', # ast.rs  Also, many .rs versions of stdlib.
    r'C:\Repos\RustPython\vm\src\vm',  # compile.rs.
    r'C:\Repos\RustPython\vm\src\stdlib\ast', # gen.rs automatically generated by ast/asdl_rs.py.
)
</t>
<t tx="ekr.20240927151701.44"></t>
<t tx="ekr.20240927151701.45"></t>
<t tx="ekr.20240927151701.46">
</t>
<t tx="ekr.20240927151701.47"></t>
<t tx="ekr.20240927151701.48"># This node contains the commands needed to execute a program in a particular language.

# Format: language-name: command

# Create a temporary file if c.p is not any kind of @&lt;file&gt; node.

# Compute the final command as follows:

# 1. If command contains &lt;FILE&gt;, replace &lt;FILE&gt; with the full path to the external file.
# 2. If command contains &lt;NO-FILE&gt;, just remove &lt;NO-FILE&gt;.
# 3. Otherwise, append the full path to the external file to the command.

go: go run . &lt;NO-FILE&gt;
python: python
rust: rustc
</t>
<t tx="ekr.20240927151701.49"># This node contains the regex pattern to determine the line number in error messages.
# Format: language-name: regex pattern
#
# Patterns must define two groups, in either order:
# One group, containing only digits, defines the line number.
# The other group defines the file name.

go: ^\s*(.*):([0-9]+):([0-9]+):.+$
python: ^\s*File "(.+)", line ([0-9]+), in .+$
rust: ^\s*--&gt; (.+):([0-9]+):([0-9]+)\s*$</t>
<t tx="ekr.20240927151701.50">cargo-run
backup
</t>
<t tx="ekr.20240927151701.51"># legacy: (default) Leo's legacy layout
# big-tree: replaces @bool big-outline-pane</t>
<t tx="ekr.20240927151701.9" __bookmarks="7d7100580700000069735f6475706571014930300a732e">@language rest
@wrap

The @settings tree contains all active settings. 

Settings outside this tree have no effect.</t>
<t tx="ekr.20240927151701.92"></t>
<t tx="ekr.20240927151701.93"></t>
<t tx="ekr.20240927151701.94">True: same as recent_files_group, except that even files (basenames) which are unique
have their containing path listed in the submenu - so visual clutter is reduced
but you can still see where things come from before you load them.

False: don't use submenus for multiple path entries, unless recent_files_group
is true (and recent_files_omit_directories is False)
</t>
<t tx="ekr.20240927151701.95"></t>
<t tx="ekr.20240927151701.96">True: show user tips on startup.</t>
<t tx="ekr.20240927151701.97"></t>
<t tx="ekr.20240927151701.98"></t>
<t tx="ekr.20240927151701.99"></t>
<t tx="ekr.20240927152759.1">@language python
g.cls()
import os
import subprocess

if c.changed:
    c.save()
command = 'cargo run'
subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240927153018.1"></t>
<t tx="ekr.20240927154009.1"></t>
<t tx="ekr.20240927154016.1">@language rest
@nowrap
@nosearch

code:

ekr-tbo-in-rust: https://github.com/edreamleo/ekr-tbo-in-rust
ruff_python_parser: https://github.com/astral-sh/ruff/tree/main/crates/ruff_python_parser/src
lexer.rs: https://github.com/astral-sh/ruff/blob/main/crates/ruff_python_parser/src/lexer.rs

docs:
Rust Book: https://doc.rust-lang.org/stable/book/title-page.html

**Summary**

- LB::make_input_list is too slow.
  This code can not be significantly faster than Leo's python beautifier!
  
- LB:beautify is not the problem. It is fast enough.
</t>
<t tx="ekr.20240927154323.1">@language rest
@wrap
@nosearch

- Use &amp;str instead of String in AnnotatedInputTok.

- Finish LB.annotate_tokens
- Finish LB:beautify.
- Can't patch InputTok with context.

Post: Use pointers, not objects.

- Pointers keep borrow checker happy, provided lifetimes are given.
</t>
<t tx="ekr.20240928073118.1">@language python
g.cls()
import os
import subprocess

if c.changed:
    c.save()
command = 'cargo fmt'
subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240928185643.1">@language rest
@wrap

Python (with extra tracing code in tbo.init_tokens_from_file:

&gt; python -c "import leo.core.leoTokens" --all --report leo\core\leoFrame.py
tbo: 0.03 sec. dirty: 0   checked: 1   beautified: 0   in leo\core\leoFrame.py

       read:   0.28 ms
make_tokens:  29.45 ms
      total:  29.73 ms
      
Rust, with nanosecond resolution.

 leoFrame.py

leoFrame.py

     files: 1, tokens: 14619, ws tokens: 5156
       read:    0.5 ms
make_tokens:   14.2 ms  Full code, without slices.
make_tokens:   11.4 ms Full code, with slices
make_tokens:   10.7 ms  Empty loop
   beautify:    7.3 ms
      write:    0.00 ms
      total:   22.08 ms
      
This only 10% faster than the python code.
</t>
<t tx="ekr.20240929024648.113">fn make_input_list(
    contents: &amp;str,
    input_list: &amp;mut Vec&lt;InputTok&gt;,
) -&gt; (usize, usize) {
    // Add InputToks to the input_list for every token given by the RustPython lex.
    // The gem: Generate "ws" pseudo-tokens for all whitespace.
    let mut tokens_n: usize = 0;
    let mut ws_tokens_n: usize = 0;
    let mut prev_start: usize = 0;
    for token_tuple in lex(&amp;contents, Mode::Module)
        .map(|tok| tok.expect("Failed to lex"))
        .collect::&lt;Vec&lt;_&gt;&gt;()
    {
        use Tok::*;
        tokens_n += 1;
        let (token, range) = token_tuple;
        let tok_value = &amp;contents[range];
        let start_i: usize = usize::from(range.start());
        let end_i: usize = usize::from(range.end());
        
        // The gem: create a whitespace pseudo-tokens.
        if start_i &gt; prev_start {
            let ws = &amp;contents[prev_start..start_i];
            add_input_token(input_list, "ws", ws);
            ws_tokens_n += 1
        }
        prev_start = end_i;

        // Variants names are necessary, but otherwise not used.
        #[allow(unused_variables)]
        
        let class_name = match token {
            // Tokens with values...
            // Use tok_value for *all* values.
            Comment(value) =&gt; "Comment",  // No idea why parens are needed here.
            Complex { real, imag } =&gt; "Complex",
            Float { value } =&gt; "Float",
            Int { value } =&gt; "Int",
            Name { name } =&gt; "Name",
            Tok::String { value, kind, triple_quoted } =&gt; "String",
            
            // Common tokens...
            Class =&gt; "Class",
            Dedent =&gt; "Dedent",
            Def =&gt; "Def",
            Indent =&gt; "Indent",
            Newline =&gt; "Newline",
            NonLogicalNewline =&gt; "NonLogicalNewline",

            // All other tokens...
            Amper =&gt; "Amper",
            AmperEqual =&gt; "AmperEqual",
            And =&gt; "And",
            As =&gt; "As",
            Assert =&gt; "Assert",
            Async =&gt; "Async",
            At =&gt; "At",
            AtEqual =&gt; "AtEqual",
            Await =&gt; "Await",
            Break =&gt; "Break",
            Case =&gt; "Case",
            CircumFlex =&gt; "CircumFlex",
            CircumflexEqual =&gt; "CircumflexEqual",
            Colon =&gt; "Colon",
            ColonEqual =&gt; "ColonEqual",
            Comma =&gt; "Comma",
            Continue =&gt; "Continue",
            Del =&gt; "Del",
            Dot =&gt; "Dot",
            DoubleSlash =&gt; "DoubleSlash",
            DoubleSlashEqual =&gt; "DoubleSlashEqual",
            DoubleStar =&gt; "DoubleStar",
            DoubleStarEqual =&gt; "DoubleStarEqual",
            Elif =&gt; "Elif",
            Ellipsis =&gt; "Ellipsis",
            Else =&gt; "Else",
            EndOfFile =&gt; "EndOfFile",
            EqEqual =&gt; "EqEqual",
            Equal =&gt; "Equal",
            Except =&gt; "Except",
            False =&gt; "False",
            Finally =&gt; "Finally",
            For =&gt; "For",
            From =&gt; "From",
            Global =&gt; "Global",
            Greater =&gt; "Greater",
            GreaterEqual =&gt; "GreaterEqual",
            If =&gt; "If",
            Import =&gt; "Import",
            In =&gt; "In",
            Is =&gt; "Is",
            Lambda =&gt; "Lambda",
            Lbrace =&gt; "Lbrace",
            LeftShift =&gt; "LeftShift",
            LeftShiftEqual =&gt; "LeftShiftEqual",
            Less =&gt; "Less",
            LessEqual =&gt; "LessEqual",
            Lpar =&gt; "Lpar",
            Lsqb =&gt; "Lsqb",
            Match =&gt; "Match",
            Minus =&gt; "Minus",
            MinusEqual =&gt; "MinusEqual",
            None =&gt; "None",
            Nonlocal =&gt; "Nonlocal",
            Not =&gt; "Not",
            NotEqual =&gt; "NotEqual",
            Or =&gt; "Or",
            Pass =&gt; "Pass",
            Percent =&gt; "Percent",
            PercentEqual =&gt; "PercentEqual",
            Plus =&gt; "Plus",
            PlusEqual =&gt; "PlusEqual",
            Raise =&gt; "Raise",
            Rarrow =&gt; "Rarrow",
            Rbrace =&gt; "Rbrace",
            Return =&gt; "Return",
            RightShift =&gt; "RightShift",
            RightShiftEqual =&gt; "RightShiftEqual",
            Rpar =&gt; "Rpar",
            Rsqb =&gt; "Rsqb",
            Semi =&gt; "Semi",
            Slash =&gt; "Slash",
            SlashEqual =&gt; "SlashEqual",
            Star =&gt; "Star",
            StarEqual =&gt; "StarEqual",
            StartExpression =&gt; "StartExpression",
            StartInteractive =&gt; "StartInteractive",
            StartModule =&gt; "StartModule",
            Tilde =&gt; "Tilde",
            True =&gt; "True",
            Try =&gt; "Try",
            Type =&gt; "Type",
            Vbar =&gt; "Vbar",
            VbarEqual =&gt; "VbarEqual",
            While =&gt; "While",
            With =&gt; "With",
            Yield =&gt; "Yield",
        };
        // add_input_token(&amp;mut input_list, class_name, tok_value);
        add_input_token(input_list, class_name, tok_value);
    }
    return (tokens_n, ws_tokens_n);
}
</t>
<t tx="ekr.20240929024648.120">#[derive(Clone, Debug)]
struct InputTok&lt;'a&gt; {
    kind: &amp;'a str,
    value: &amp;'a str,
}

impl &lt;'a&gt; InputTok&lt;'_&gt; {
    fn new(kind: &amp;'a str, value: &amp;'a str) -&gt; InputTok&lt;'a&gt; {
        InputTok {
            kind: kind,
            value: value,
        }
    }
}
</t>
<t tx="ekr.20240929031635.1">fn scan_input_list(contents: String, tokens: Vec&lt;(Tok, TextRange)&gt;) -&gt; usize {

    let mut count: usize = 0;
    for (token, range) in tokens {
        // Range is a TextRange.
        count += 1;
        // To do: Find gaps in the ranges.
        let start_i = usize::from(range.start());
        let end_i = usize::from(range.end());
        if false {
            if count &lt; 20 {
                println!("{start_i:&gt;3}..{end_i:3} token: {token:?}");
            }
        }
    }
    return count;
}
</t>
<t tx="ekr.20240929032636.1">pub fn entry() {
    // leoFrame.py is a typical size
    let file_path = "C:\\Repos\\leo-editor\\leo\\core\\leoFrame.py";
    let short_file_name = "leoFrame.py";
    &lt;&lt; 1: read &gt;&gt;
    &lt;&lt; 2: Make input_list &gt;&gt;
    &lt;&lt; 3: print stats &gt;&gt;
}
</t>
<t tx="ekr.20240929032710.1">fn fmt_ms(t: u128) -&gt; String {
    //! Convert microseconds to fractional milliseconds.
    let ms = t / 1000;
    let micro = (t % 1000) / 10;
    return f!("{ms}.{micro:02}");  // Two-digits for fraction.
}

</t>
<t tx="ekr.20240929033044.1">fn add_input_token (input_list: &amp;mut Vec&lt;InputTok&gt;, kind: &amp;str, value: &amp;str) {
    //! Add one token to the output list.
    let new_tok = InputTok {
        kind: kind.to_string(),
        value: value.to_string()
    };
    input_list.push(new_tok);
}
</t>
<t tx="ekr.20240929074037.1">#[derive(Debug)]

pub struct Beautifier {
    // Set in LB:beautify_one_file...
    args: Vec&lt;String&gt;,
    files_list: Vec&lt;String&gt;,
    stats: Stats,
    output_list: Vec&lt;String&gt;,
}

///// Temporary.
#[allow(dead_code)]
#[allow(non_snake_case)]
impl Beautifier {
    @others
}
</t>
<t tx="ekr.20240929074037.10">fn do_Complex(&amp;mut self, tok_value: &amp;str) {
    self.add_output_string("Complex", tok_value);
}
</t>
<t tx="ekr.20240929074037.100">fn do_StartModule(&amp;mut self) {
    // self.add_output_string("StartModule", "");
    println!("do_StartModule");
}
</t>
<t tx="ekr.20240929074037.101">fn do_Tilde(&amp;mut self) {
    self.add_output_string("Tilde", "~");
}
</t>
<t tx="ekr.20240929074037.102">fn do_True(&amp;mut self) {
    self.add_output_string("True", "True");
}
</t>
<t tx="ekr.20240929074037.103">fn do_Try(&amp;mut self) {
    self.add_output_string("Try", "try");
}
</t>
<t tx="ekr.20240929074037.104">fn do_Type(&amp;mut self) {
    self.add_output_string("Type", "type");
}
</t>
<t tx="ekr.20240929074037.105">fn do_Vbar(&amp;mut self) {
    self.add_output_string("Vbar", "|");
}
</t>
<t tx="ekr.20240929074037.106">fn do_VbarEqual(&amp;mut self) {
    self.add_output_string("VbarEqual", "|=");
}
</t>
<t tx="ekr.20240929074037.107">fn do_While(&amp;mut self) {
    self.add_output_string("While", "while");
}
</t>
<t tx="ekr.20240929074037.108">fn do_With(&amp;mut self) {
    self.add_output_string("With", "with");
}
</t>
<t tx="ekr.20240929074037.109">fn do_Yield(&amp;mut self) {
    self.add_output_string("Yield", "yield");
}
</t>
<t tx="ekr.20240929074037.11">fn do_Float(&amp;mut self, tok_value: &amp;str) {
    self.add_output_string("Float", tok_value);
}
</t>
<t tx="ekr.20240929074037.110">fn enabled(&amp;self, arg: &amp;str) -&gt; bool {
    //! Beautifier::enabled: return true if the given command-line argument is enabled.
    //! Example:  x.enabled("--report");
    return self.args.contains(&amp;arg.to_string());
}
</t>
<t tx="ekr.20240929074037.111">fn get_args(&amp;mut self) {
    //! Beautifier::get_args: Set the args and files_list ivars.
    let args: Vec&lt;String&gt; = env::args().collect();
    let valid_args = vec![
        "--all",
        "--beautified",
        "--diff",
        "-h",
        "--help",
        "--report",
        "--write",
    ];
    for (i, arg) in args.iter().enumerate() {
        if i &gt; 0 {
            if valid_args.contains(&amp;arg.as_str()) {
                self.args.push(arg.to_string())
            } else if arg.as_str().starts_with("--") || arg.as_str().starts_with("--") {
                println!("Ignoring invalid arg: {arg}");
            } else {
                println!("File: {arg}");
                self.files_list.push(arg.to_string());
            }
        }
    }
}
</t>
<t tx="ekr.20240929074037.112">fn make_input_list&lt;'a&gt;(&amp;mut self, contents: &amp;'a str) -&gt; Vec&lt;InputTok&lt;'a&gt;&gt; {
    //! Return an input_list from the tokens given by the RustPython lex.
    let mut n_tokens: u64 = 0;
    let mut n_ws_tokens: u64 = 0;
    let mut prev_start: usize = 0;
    let mut result: Vec&lt;InputTok&gt; = Vec::new();
    for token_tuple in lex(&amp;contents, Mode::Module)
        .map(|tok| tok.expect("Failed to lex"))
        .collect::&lt;Vec&lt;_&gt;&gt;()
    {
        use Tok::*;
        let (token, range) = token_tuple;
        let tok_value = &amp;contents[range];

        // The gem: create a whitespace pseudo-tokens.
        // This code adds maybe about 1 ms when beautifying leoFrame.py.
        // With the gem: 14.1 - 14.5 ms. Without: 13.1 - 13.7 ms.
        let start_i = usize::from(range.start());
        let end_i = usize::from(range.end());
        if start_i &gt; prev_start {
            let ws = &amp;contents[prev_start..start_i];
            result.push(InputTok::new("ws", ws));
            n_ws_tokens += 1
        }
        prev_start = end_i;

        &lt;&lt; Calculate class_name using match token &gt;&gt;
        n_tokens += 1;
        result.push(InputTok::new(class_name, tok_value));
    }
    // Update counts.
    self.stats.n_tokens += n_tokens;
    self.stats.n_ws_tokens += n_ws_tokens;
    return result;
}
</t>
<t tx="ekr.20240929074037.113">fn beautify(&amp;mut self, annotated_list: &amp;Vec&lt;AnnotatedInputTok&gt;) -&gt; String {
    //! Beautify the input_tokens, creating the output String.
    for input_token in annotated_list {
        &lt;&lt; LB: beautify: dispatch on input_token.kind &gt;&gt;
    }
    // return ''.join(self.output_list);
    let mut result = String::new();
    for output_token in &amp;self.output_list {
        result.push_str(output_token);
    }
    if false {
        let n = result.len();
        println!("result: {n} characters");
    }
    return result;
}
</t>
<t tx="ekr.20240929074037.114">pub fn new() -&gt; Beautifier {
    let mut x = Beautifier {
        // Set in beautify_one_file
        args: Vec::new(),
        files_list: Vec::new(),
        output_list: Vec::new(),
        stats: Stats::new(),
    };
    x.get_args();
    return x;
}
</t>
<t tx="ekr.20240929074037.115">fn show_args(&amp;self) {
    println!("Command-line arguments...");
    for (i, arg) in self.args.iter().enumerate() {
        if i &gt; 0 {
            println!("  {arg}");
        }
    }
    for file_arg in self.files_list.iter() {
        println!("  {file_arg}");
    }
}
</t>
<t tx="ekr.20240929074037.116">fn show_help(&amp;self) {
    //! Beautifier::show_help: print the help messages.
    println!(
        "{}",
        textwrap::dedent(
            "
        Beautify or diff files.

        -h --help:      Print this help message and exit.
        --all:          Beautify all files, even unchanged files.
        --beautified:   Report beautified files individually, even if not written.
        --diff:         Show diffs instead of changing files.
        --report:       Print summary report.
        --write:        Write beautifed files (dry-run mode otherwise).
    "
        )
    );
}
</t>
<t tx="ekr.20240929074037.117">fn show_output_list(&amp;self) {
    println!("\nOutput list...");
    for (i, arg) in self.output_list.iter().enumerate() {
        if i &gt; 0 {
            print!("{:?}", arg);
        }
    }
}
</t>
<t tx="ekr.20240929074037.12">fn do_Int(&amp;mut self, tok_value: &amp;str) {
    self.add_output_string("Int", tok_value);
}
</t>
<t tx="ekr.20240929074037.13">fn do_Name(&amp;mut self, tok_value: &amp;str) {
    self.add_output_string("Name", tok_value);
}
</t>
<t tx="ekr.20240929074037.14">fn do_String(&amp;mut self, tok_value: &amp;str) {
    // correct.
    // print!("{tok_value}");

    // incorrect.
    // let quote = if *triple_quoted {"'''"} else {"'"};
    // print!("{:?}:{quote}{value}{quote}", kind);

    self.add_output_string("String", tok_value);
}
</t>
<t tx="ekr.20240929074037.15"></t>
<t tx="ekr.20240929074037.16">fn do_Dedent(&amp;mut self, tok_value: &amp;str) {
    self.add_output_string("Dedent", tok_value);
}
</t>
<t tx="ekr.20240929074037.17">fn do_Indent(&amp;mut self, tok_value: &amp;str) {
    self.add_output_string("Indent", tok_value);
}
</t>
<t tx="ekr.20240929074037.18">fn do_Newline(&amp;mut self) {
    self.add_output_string("Indent", "\n");
}
</t>
<t tx="ekr.20240929074037.19">fn do_NonLogicalNewline(&amp;mut self) {
    self.add_output_string("Indent", "\n");
}
</t>
<t tx="ekr.20240929074037.2">#[allow(unused_variables)]
fn add_output_string(&amp;mut self, kind: &amp;str, value: &amp;str) {
    //! Add value to the output list.
    //! kind is for debugging.
    if !value.is_empty() {
        self.output_list.push(value.to_string())
    }
}
</t>
<t tx="ekr.20240929074037.20"></t>
<t tx="ekr.20240929074037.21">fn do_Amper(&amp;mut self) {
    self.add_output_string("Amper", "&amp;");
}
</t>
<t tx="ekr.20240929074037.22">fn do_AmperEqual(&amp;mut self) {
    self.add_output_string("AmperEqual", "&amp;=");
}
</t>
<t tx="ekr.20240929074037.23">fn do_And(&amp;mut self) {
    self.add_output_string("And", "and");
}
</t>
<t tx="ekr.20240929074037.24">fn do_As(&amp;mut self) {
    self.add_output_string("As", "as");
}
</t>
<t tx="ekr.20240929074037.25">fn do_Assert(&amp;mut self) {
    self.add_output_string("Assert", "assert");
}
</t>
<t tx="ekr.20240929074037.26">fn do_Async(&amp;mut self) {
    self.add_output_string("Async", "async");
}
</t>
<t tx="ekr.20240929074037.27">fn do_At(&amp;mut self) {
    self.add_output_string("At", "@");
}
</t>
<t tx="ekr.20240929074037.28">fn do_AtEqual(&amp;mut self) {
    self.add_output_string("AtEqual", "@=");
}
</t>
<t tx="ekr.20240929074037.29">fn do_Await(&amp;mut self) {
    self.add_output_string("Await", "await");
}
</t>
<t tx="ekr.20240929074037.3">// #[allow(dead_code)]
fn add_input_token(&amp;mut self, kind: &amp;str, value: &amp;str) {
    //! Add one token to the output list.
    self.input_list.push(InputTok {
        kind: kind.to_string(),
        value: value.to_string(),
    });
}
</t>
<t tx="ekr.20240929074037.30">fn do_Break(&amp;mut self) {
    self.add_output_string("Break", "break");
}
</t>
<t tx="ekr.20240929074037.31">fn do_Case(&amp;mut self) {
    self.add_output_string("Case", "case");
}
</t>
<t tx="ekr.20240929074037.32">fn do_CircumFlex(&amp;mut self) {
    self.add_output_string("CircumFlex", "^");
}
</t>
<t tx="ekr.20240929074037.33">fn do_CircumflexEqual(&amp;mut self) {
    self.add_output_string("CircumflexEqual", "^=");
}
</t>
<t tx="ekr.20240929074037.34">fn do_Class(&amp;mut self) {
    self.add_output_string("Class", "class");
}
</t>
<t tx="ekr.20240929074037.35">fn do_Colon(&amp;mut self) {
    self.add_output_string("Colon", ":");
}
</t>
<t tx="ekr.20240929074037.36">fn do_ColonEqual(&amp;mut self) {
    self.add_output_string("ColonEqual", ":=");
}
</t>
<t tx="ekr.20240929074037.37">fn do_Comma(&amp;mut self) {
    self.add_output_string("Comma", ",");
}
</t>
<t tx="ekr.20240929074037.38">fn do_Continue(&amp;mut self) {
    self.add_output_string("Continue", "continue");
}
</t>
<t tx="ekr.20240929074037.39">fn do_Def(&amp;mut self) {
    self.add_output_string("Def", "def");
}
</t>
<t tx="ekr.20240929074037.4">pub fn beautify_all_files(&amp;mut self) {
    // for file_name in self.files_list.clone() {
    for file_name in self.files_list.clone() {
        self.beautify_one_file(&amp;file_name);
    }
}

</t>
<t tx="ekr.20240929074037.40">fn do_Del(&amp;mut self) {
    self.add_output_string("Del", "del");
}
</t>
<t tx="ekr.20240929074037.41">fn do_Dot(&amp;mut self) {
    self.add_output_string("Dot", ".");
}
</t>
<t tx="ekr.20240929074037.42">fn do_DoubleSlash(&amp;mut self) {
    self.add_output_string("DoubleSlash", "//");
}
</t>
<t tx="ekr.20240929074037.43">fn do_DoubleSlashEqual(&amp;mut self) {
    self.add_output_string("DoubleSlashEqual", "//=");
}
</t>
<t tx="ekr.20240929074037.44">fn do_DoubleStar(&amp;mut self) {
    self.add_output_string("DoubleStar", "**");
}
</t>
<t tx="ekr.20240929074037.45">fn do_DoubleStarEqual(&amp;mut self) {
    self.add_output_string("DoubleStarEqual", "**=");
}
</t>
<t tx="ekr.20240929074037.46">fn do_Elif(&amp;mut self) {
    self.add_output_string("Elif", "elif");
}
</t>
<t tx="ekr.20240929074037.47">fn do_Ellipsis(&amp;mut self) {
    self.add_output_string("Ellipsis", "...");
}
</t>
<t tx="ekr.20240929074037.48">fn do_Else(&amp;mut self) {
    self.add_output_string("Else", "else");
}
</t>
<t tx="ekr.20240929074037.49">fn do_EndOfFile(&amp;mut self) {
    self.add_output_string("EndOfFile", "EOF");
}
</t>
<t tx="ekr.20240929074037.5">fn beautify_one_file(&amp;mut self, file_name: &amp;str) {
    self.stats.n_files += 1;
    if true {
        // Testing only: print the short file name.
        let file_path = path::Path::new(file_name);
        let os_str = file_path.file_name().unwrap(); // &amp;OsStr
        let short_file_name = os_str.to_str().unwrap();
        println!("{short_file_name}");
    }
    // Read the file into contents (a String).
    let t1 = std::time::Instant::now();
    let contents = fs::read_to_string(file_name).expect("Error reading{file_name}");
    self.stats.read_time += t1.elapsed().as_nanos();
    // Create (an immutable!) list of input tokens.
    let t2 = std::time::Instant::now();
    let input_tokens = self.make_input_list(&amp;contents);
    self.stats.make_tokens_time += t2.elapsed().as_nanos();
    // Annotate tokens (the prepass).
    let t3 = std::time::Instant::now();
    let annotated_tokens = self.annotate_tokens(&amp;input_tokens);
    self.stats.annotation_time += t3.elapsed().as_nanos();
    // Beautify.
    let t4 = std::time::Instant::now();
    self.beautify(&amp;annotated_tokens);
    self.stats.beautify_time += t4.elapsed().as_nanos();
}
</t>
<t tx="ekr.20240929074037.50">fn do_EqEqual(&amp;mut self) {
    self.add_output_string("EqEqual", "==");
}
</t>
<t tx="ekr.20240929074037.51">fn do_Equal(&amp;mut self) {
    self.add_output_string("Equal", "=");
}
</t>
<t tx="ekr.20240929074037.52">fn do_Except(&amp;mut self) {
    self.add_output_string("Except", "except");
}
</t>
<t tx="ekr.20240929074037.53">fn do_False(&amp;mut self) {
    self.add_output_string("False", "False");
}
</t>
<t tx="ekr.20240929074037.54">fn do_Finally(&amp;mut self) {
    self.add_output_string("Finally", "finally");
}
</t>
<t tx="ekr.20240929074037.55">fn do_For(&amp;mut self) {
    self.add_output_string("For", "for");
}
</t>
<t tx="ekr.20240929074037.56">fn do_From(&amp;mut self) {
    self.add_output_string("From", "from");
}
</t>
<t tx="ekr.20240929074037.57">fn do_Global(&amp;mut self) {
    self.add_output_string("Global", "global");
}
</t>
<t tx="ekr.20240929074037.58">fn do_Greater(&amp;mut self) {
    self.add_output_string("Greater", "&gt;");
}
</t>
<t tx="ekr.20240929074037.59">fn do_GreaterEqual(&amp;mut self) {
    self.add_output_string("GreaterEqual", "&gt;-");
}
</t>
<t tx="ekr.20240929074037.60">fn do_If(&amp;mut self) {
    self.add_output_string("If", "if");
}
</t>
<t tx="ekr.20240929074037.61">fn do_Import(&amp;mut self) {
    self.add_output_string("Import", "import");
}
</t>
<t tx="ekr.20240929074037.62">fn do_In(&amp;mut self) {
    self.add_output_string("In", "in");
}
</t>
<t tx="ekr.20240929074037.63">fn do_Is(&amp;mut self) {
    self.add_output_string("Is", "is");
}
</t>
<t tx="ekr.20240929074037.64">fn do_Lambda(&amp;mut self) {
    self.add_output_string("Lambda", "lambda");
}
</t>
<t tx="ekr.20240929074037.65">fn do_Lbrace(&amp;mut self) {
    self.add_output_string("Lbrace", "[");
}
</t>
<t tx="ekr.20240929074037.66">fn do_LeftShift(&amp;mut self) {
    self.add_output_string("LeftShift", "&lt;&lt;");
}
</t>
<t tx="ekr.20240929074037.67">fn do_LeftShiftEqual(&amp;mut self) {
    self.add_output_string("LeftShiftEqual", "&lt;&lt;=");
}
</t>
<t tx="ekr.20240929074037.68">fn do_Less(&amp;mut self) {
    self.add_output_string("Less", "&lt;");
}
</t>
<t tx="ekr.20240929074037.69">fn do_LessEqual(&amp;mut self) {
    self.add_output_string("LessEqual", "&lt;=");
}
</t>
<t tx="ekr.20240929074037.7"></t>
<t tx="ekr.20240929074037.70">fn do_Lpar(&amp;mut self) {
    self.add_output_string("Lpar", "(");
}
</t>
<t tx="ekr.20240929074037.71">fn do_Lsqb(&amp;mut self) {
    self.add_output_string("Lsqb", "[");
}
</t>
<t tx="ekr.20240929074037.72">fn do_Match(&amp;mut self) {
    self.add_output_string("Match", "match");
}
</t>
<t tx="ekr.20240929074037.73">fn do_Minus(&amp;mut self) {
    self.add_output_string("Minus", "-");
}
</t>
<t tx="ekr.20240929074037.74">fn do_MinusEqual(&amp;mut self) {
    self.add_output_string("MinusEqual", "-=");
}
</t>
<t tx="ekr.20240929074037.75">fn do_None(&amp;mut self) {
    self.add_output_string("None", "None");
}
</t>
<t tx="ekr.20240929074037.76">fn do_Nonlocal(&amp;mut self) {
    self.add_output_string("Nonlocal", "nonlocal");
}
</t>
<t tx="ekr.20240929074037.77">fn do_Not(&amp;mut self) {
    self.add_output_string("Not", "not");
}
</t>
<t tx="ekr.20240929074037.78">fn do_NotEqual(&amp;mut self) {
    self.add_output_string("NotEqual", "!=");
}
</t>
<t tx="ekr.20240929074037.79">fn do_Or(&amp;mut self) {
    self.add_output_string("Or", "or");
}
</t>
<t tx="ekr.20240929074037.8"></t>
<t tx="ekr.20240929074037.80">fn do_Pass(&amp;mut self) {
    self.add_output_string("Pass", "pass");
}
</t>
<t tx="ekr.20240929074037.81">fn do_Percent(&amp;mut self) {
    self.add_output_string("Percent", "%");
}
</t>
<t tx="ekr.20240929074037.82">fn do_PercentEqual(&amp;mut self) {
    self.add_output_string("PercentEqual", "%=");
}
</t>
<t tx="ekr.20240929074037.83">fn do_Plus(&amp;mut self) {
    self.add_output_string("Plus", "+");
}
</t>
<t tx="ekr.20240929074037.84">fn do_PlusEqual(&amp;mut self) {
    self.add_output_string("PlusEqual", "+=");
}
</t>
<t tx="ekr.20240929074037.85">fn do_Raise(&amp;mut self) {
    self.add_output_string("Raise", "raise");
}
</t>
<t tx="ekr.20240929074037.86">fn do_Rarrow(&amp;mut self) {
    self.add_output_string("Rarrow", "-&gt;");
}
</t>
<t tx="ekr.20240929074037.87">fn do_Rbrace(&amp;mut self) {
    self.add_output_string("Rbrace", "]");
}
</t>
<t tx="ekr.20240929074037.88">fn do_Return(&amp;mut self) {
    self.add_output_string("Return", "return");
}
</t>
<t tx="ekr.20240929074037.89">fn do_RightShift(&amp;mut self) {
    self.add_output_string("RightShift", "&gt;&gt;");
}
</t>
<t tx="ekr.20240929074037.9">fn do_Comment(&amp;mut self, tok_value: &amp;str) {
    // print!("{tok_value}");  // Correct.
    // print!("{value} ");  // Wrong!
    self.add_output_string("Comment", tok_value);
}
</t>
<t tx="ekr.20240929074037.90">fn do_RightShiftEqual(&amp;mut self) {
    self.add_output_string("RightShiftEqual", "&gt;&gt;=");
}
</t>
<t tx="ekr.20240929074037.91">fn do_Rpar(&amp;mut self) {
    self.add_output_string("Rpar", ")");
}
</t>
<t tx="ekr.20240929074037.92">fn do_Rsqb(&amp;mut self) {
    self.add_output_string("Rsqb", "]");
}
</t>
<t tx="ekr.20240929074037.93">fn do_Semi(&amp;mut self) {
    self.add_output_string("Semi", ";");
}
</t>
<t tx="ekr.20240929074037.94">fn do_Slash(&amp;mut self) {
    self.add_output_string("Slash", "/");
}
</t>
<t tx="ekr.20240929074037.95">fn do_SlashEqual(&amp;mut self) {
    self.add_output_string("SlashEqual", "/=");
}
</t>
<t tx="ekr.20240929074037.96">fn do_Star(&amp;mut self) {
    self.add_output_string("Star", "*");
}
</t>
<t tx="ekr.20240929074037.97">fn do_StarEqual(&amp;mut self) {
    self.add_output_string("StarEqual", "*=");
}
</t>
<t tx="ekr.20240929074037.98">fn do_StartExpression(&amp;mut self) {
    // self.add_output_string("StartExpression", "");
}
</t>
<t tx="ekr.20240929074037.99">fn do_StartInteractive(&amp;mut self) {
    // self.add_output_string("StartModule", "");
}
</t>
<t tx="ekr.20240929074547.1">#[derive(Debug)]
pub struct Stats {
    // Cumulative statistics for all files.
    n_files: u64,     // Number of files.
    n_tokens: u64,    // Number of tokens.
    n_ws_tokens: u64, // Number of pseudo-ws tokens.

    // Timing stat, in microseconds...
    annotation_time: u128,
    beautify_time: u128,
    make_tokens_time: u128,
    read_time: u128,
    write_time: u128,
}

// #[allow(dead_code)]
// #[allow(non_snake_case)]
impl Stats {
    @others
}
</t>
<t tx="ekr.20240929074941.1">fn update_times(
    &amp;mut self,
    beautify: u128,
    make_tokens: u128,
    read_time: u128,
    write_time: u128,
) {
    // Update cumulative timing stats.
    self.beautify_time += beautify;
    self.make_tokens_time += make_tokens;
    self.read_time += read_time;
    self.write_time += write_time;
}
</t>
<t tx="ekr.20240929075236.1">fn report(&amp;mut self) {
    // Cumulative counts.
    let n_files = self.n_files;
    let n_tokens = self.n_tokens;
    let n_ws_tokens = self.n_ws_tokens;
    // Print cumulative timing stats, in ms.
    let annotation_time = self.fmt_ns(self.annotation_time);
    let beautify_time = self.fmt_ns(self.beautify_time);
    let make_tokens_time = self.fmt_ns(self.make_tokens_time);
    let read_time = self.fmt_ns(self.read_time);
    let write_time = self.fmt_ns(self.write_time);
    let total_time_ns = self.annotation_time
        + self.beautify_time
        + self.make_tokens_time
        + self.read_time
        + self.write_time;
    let total_time = self.fmt_ns(total_time_ns);
    println!("");
    println!("     files: {n_files}, tokens: {n_tokens}, ws tokens: {n_ws_tokens}");
    println!("       read: {read_time:&gt;7} ms");
    println!("make_tokens: {make_tokens_time:&gt;7} ms");
    println!(" annotation: {annotation_time:&gt;7} ms");
    println!("   beautify: {beautify_time:&gt;7} ms");
    println!("      write: {write_time:&gt;7} ms");
    println!("      total: {total_time:&gt;7} ms");
}
</t>
<t tx="ekr.20240929080242.1">fn fmt_ns(&amp;mut self, t: u128) -&gt; String {
    //! Convert nanoseconds to fractional milliseconds.
    let ms = t / 1000000;
    let micro = (t % 1000000) / 10000; // 2-places only.
                                       // println!("t: {t:8} ms: {ms:03} micro: {micro:02}");
    return f!("{ms:4}.{micro:02}");
}

</t>
<t tx="ekr.20240929084852.1">@language rest
@wrap

Whether a value is on the stack or the heap affects how the language behaves.

Rules:
- Each value in Rust has an *owner*.
- There can only be one owner at a time.
- When the owner goes out of scope, the value will be dropped.
  **The scope ends when value last used**.

String literals can't be mutated.  String objects are on the heap and can be mutated.
The *drop* function releases heap objects.

Move is a shallow copy:
@language rust
    let s1 = String::from("hello");
    let s2 = s1;
    println!("{s1}, world!");  // wrong.
@language rest

*clone* makes a deep copy.

*small (stack-only) values are copied when passed as params*.

Stack-only values have *copy trait*.
Can't add `copy` trait if object implements `drop`.

Ownership and functions:

Passing a variable to a function will move or copy, just as assignment does. 

Return Values and Scope:

Returning values can also transfer ownership.

References and borrowing:

'&amp;' represents a reference.
References are immutable by defaault.
If you have a mutable reference to a value, you can have no other references to that value. 

Rules of reference:

- At any time, you can have either one mutable reference or any number of immutable references.
- References must always be valid.
</t>
<t tx="ekr.20240930063514.1">@language python
import os
import subprocess

if c.changed:
    c.save()
command = 'git commit'
subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240930063546.1">@language python
import os
import subprocess

if c.changed:
    c.save()
command = 'git status'
subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240930063740.1">@language python
import os
import subprocess

if c.changed:
    c.save()
for command in ('git add *.rs', 'git status'):
    subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240930064435.1">@language python
import os
import subprocess

if c.changed:
    c.save()
command = 'git reset'
subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240930064622.1">@language python
import os
import subprocess
if c.changed:
    c.save()
command = 'git push'
subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20240930084648.1">fn read(file_path: &amp;str) -&gt; String {
    let error_s = f!("Can not read {file_path}");
    return fs::read_to_string(file_path).expect(&amp;error_s);
}
</t>
<t tx="ekr.20240930085546.1">fn lex_contents(contents: &amp;str) -&gt; Vec&lt;(Tok, TextRange)&gt; {
    return lex(&amp;contents, Mode::Module)
        .map(|tok| tok.expect("Failed to lex"))
        .collect::&lt;Vec&lt;_&gt;&gt;();
}
</t>
<t tx="ekr.20240930100553.1">// Compute cumulative stats.
let total_time = fmt_ms(t1.elapsed().as_micros());
let tokens_n = input_list.len();
println!("");
println!("tbo: {short_file_name}");
println!("{n_tokens} lex tokens, {ws_tokens_n} ws_tokens, len(input_list): {tokens_n}");
println!("");
println!("       read: {read_time:&gt;5} ms");
// println!("        lex: {lex_time:&gt;5} ms");
println!("make_tokens: {loop_time:&gt;5} ms");
println!("      total: {total_time:&gt;5} ms");
</t>
<t tx="ekr.20240930100625.1">let t1 = Instant::now();
let contents = read(&amp;file_path);
let read_time = fmt_ms(t1.elapsed().as_micros());
</t>
<t tx="ekr.20240930100707.1">let t4 = Instant::now();
let mut input_list: Vec&lt;InputTok&gt; = Vec::new();
let (n_tokens, ws_tokens_n) = make_input_list(&amp;contents, &amp;mut input_list); ////, tokens);
let loop_time = fmt_ms(t4.elapsed().as_micros());
</t>
<t tx="ekr.20240930101156.1">@language python
import os
import subprocess

if c.changed:
    c.save()
for command in ('git add *.leo', 'git status'):
    subprocess.Popen(command, shell=True).communicate()
</t>
<t tx="ekr.20241001055017.1">@language rust

// A trait defines the functionality a particular type has and can share with other types. 
// Traits are like interfaces.

pub trait Summary {
    fn summarize(&amp;self) -&gt; String;
}

impl Summary for NewsArticle {
    fn summarize(&amp;self) -&gt; String {
        format!("{}, by {} ({})",, self.author, self.location)
    }
}

// Traits can have default implementations for some or all functions.
pub trait Summary {
    fn summarize_author(&amp;self) -&gt; String;

    fn summarize(&amp;self) -&gt; String {
        format!("(Read more from {}...)", self.summarize_author())
    }
}

// ***&amp; Traits as parameters: var: &amp;impl TraitName.

pub fn notify(item1: &amp;impl Summary, item2: &amp;impl Summary) {...}

// *** Trait-bound syntax.  &lt;T: Trait&gt;(item: &amp;T).

pub fn notify&lt;T: Summary&gt;(item1: &amp;T, item2: &amp;T) {...}

// *** Multiple trait bounds Trail + Trait

pub fn notify(item: &amp;(impl Summary + Display)) {...}

pub fn notify&lt;T: Summary + Display&gt;(item: &amp;T) {...}

// *** Where syntax:

fn some_function&lt;T: Display + Clone, U: Clone + Debug&gt;(t: &amp;T, u: &amp;U) -&gt; i32 {...}

fn some_function&lt;T, U&gt;(t: &amp;T, u: &amp;U) -&gt; i32
where
    T: Display + Clone,
    U: Clone + Debug,
{...}

// *** Returning types that implement traits:

// The function can only return a single type.

fn returns_summarizable() -&gt; impl Summary {...}

// The ability to specify a return type only by the trait it implements is
// especially useful in the context of closures and iterators.

// We can call o.to_string method defined by the ToString trait on
// any type that implements the Display trait. 
</t>
<t tx="ekr.20241001060848.1">When returning a reference from a function,
the lifetime parameter for the return type needs to match the lifetime parameter for one of the parameters.</t>
<t tx="ekr.20241001071914.1">fn test_loop(contents: &amp;str) {
    let mut n_tokens = 0;
    for token in lex(&amp;contents, Mode::Module)
        .map(|tok| tok.expect("Failed to lex"))
        .collect::&lt;Vec&lt;_&gt;&gt;()
    {
        if n_tokens &lt; 10 {
            println!("token: {token:?}")
        }
        n_tokens += 1;
    }
    println!("tokens: {n_tokens}")
}
</t>
<t tx="ekr.20241001073040.1">@nosearch</t>
<t tx="ekr.20241001093308.2">fn tokenize() {
    &lt;&lt; tokenize: define contents &gt;&gt;
    println!("fn tokenize");
    println!("\nSource:\n{contents}");

    for debug in [true, false].iter() {

        println!("{}", if *debug {"Tokens..."} else {"\nBeautified:"});

        let results = lex(contents, Mode::Module);  // An iterator yielding Option(Tok).
        let mut count = 0;
        let mut lws = String::new();
        for (i, result) in results.enumerate() {
            use Tok::*;
            let token = result.ok().unwrap();
            let (ref tok_class, tok_range) = token;
            let tok_value = &amp;contents[tok_range];

            if *debug {
                let s = format!("{tok_class}");
                print!("\nToken: {s:20} {:?}", tok_value);
            }
            else {
                // Comment(value), Name(name)
                #[allow(unused_variables)]
                match tok_class {
                    Comment(value) =&gt; {
                        // print!("{value} ");  // Wrong!
                        print!("{tok_value}");
                    },
                    Dedent =&gt; {
                        lws.pop();
                        lws.pop();
                        print!("{lws}");
                    },
                    Def =&gt; {
                        print!("{tok_value} ");
                    },
                    Indent =&gt; {
                        lws.push_str("    ");
                        print!("{lws}");
                    },
                    Name {name} =&gt; {
                        print!("{tok_value} ");
                    },
                    Newline =&gt; {
                        print!("{tok_value}");
                        print!("{lws}");
                        if false {  // old
                            println!("");
                            print!("{lws}");
                        }
                    },
                    NonLogicalNewline =&gt; {
                        println!("");
                        print!("{lws}");
                    },
                    Return =&gt; {
                        print!("{tok_value} ");
                    },
                    Tok::String {value, kind, triple_quoted} =&gt; {
                        // correct.
                        print!("{tok_value}");
                        if false {  // incorrect.
                            let quote = if *triple_quoted {"'''"} else {"'"};
                            print!("{:?}:{quote}{value}{quote}", kind);
                        }
                    },
                    _ =&gt; {
                        print!("{tok_value}");
                        if false {
                            // to_string quotes values!
                            let s = tok_class.to_string().replace("'", "");
                            print!("{s}");
                        }
                    },
                }
            }
            count = i
        }
        if *debug {
            println!("\n{count} tokens")
        }
    }
}
</t>
<t tx="ekr.20241001093308.3">let contents = r#"
def test():
# Comment 1.
print('abc')
# Comment 2.
"#;

// print("xyz")
// print(rf'pdb')
// print(fr'pdb2')
// return bool(i &amp; 1)
</t>
<t tx="ekr.20241001100954.1">pub fn new() -&gt; Stats {
    let x = Stats {
        // Cumulative counts.
        n_files: 0,     // Number of files.
        n_tokens: 0,    // Number of tokens.
        n_ws_tokens: 0, // Number of pseudo-ws tokens.

        // Timing stats, in nanoseconds...
        annotation_time: 0,
        beautify_time: 0,
        make_tokens_time: 0,
        read_time: 0,
        write_time: 0,
    };
    return x;
}
</t>
<t tx="ekr.20241001104914.1"></t>
<t tx="ekr.20241001213229.1">@language rust

    // def no_visitor(self) -&gt; String:  # pragma: no cover
    //    self.oops(f"Unknown kind: {self.input_token.kind!r}")

    &lt;&lt; LB::beautify: init ivars &gt;&gt;

    try:
        // Pre-scan the token list, setting context.s
        self.pre_scan();

        // Init ivars first.
        self.input_token = None;  // ???
        self.pending_lws = "";  // ???
        self.pending_ws = "";  // ???
        self.prev_output_kind = None;    // ???
        self.prev_output_value = None;  // ???

        // Init state.
        self.gen_token("file-start", "");
        self.push_state("file-start");

        // The main loop:
        prev_line_number: i32 = 0;
        for (self.index, self.input_token) in enumerate(input_tokens):
            // Set global for visitors.
            if prev_line_number != self.input_token.line_number {
                prev_line_number = self.input_token.line_number;
            }
            // Call the proper visitor.
            if self.verbatim {
                self.do_verbatim();
            } else {
                // Use match ???
                func = getattr(self, f"do_{self.input_token.kind}", self.no_visitor)
                func()
            }

        // Return the result. ???
        // result = ''.join(self.output_list);
        let mut result = String::new();
        for s in self.output_list {
            result.push_str(s);
        }
        return result;
</t>
<t tx="ekr.20241002054443.1">@language rust

// The clone in LB:beautify appears to be necessary.

// All these FAIL in LB::beautify
 
self.add_output_string(&amp;"Test", &amp;"Value");  // mutable borrow occurs here.
self.output_list.push(&amp;input_token.value); //  expected `String`, found `&amp;String`
self.output_list.push("Value");  // expected `String`, found `&amp;str`
self.output_list.push(&amp;"Value");  // expected `String`, found `&amp;&amp;str`

// Works.
self.output_list.push(input_token.value.to_string());  // Converts str to String
self.output_list.push("value".to_string());  // Converts str to String

// Dispatch

// let kind = &amp;input_token.kind.to_string();  // expected `&amp;String`, found `&amp;str`
// let kind = &amp;input_token.kind; // expected `&amp;String`, found `&amp;str`

// immutable borrow occurs here
    // let kind_s = &amp;input_token.kind;
    // let kind = kind_s.as_str();
    </t>
<t tx="ekr.20241002062655.1">let kind = input_token.kind.as_str();
let value = input_token.kind.as_str();
match kind {
    // Some of these could be replaced by inline code.
    "And" =&gt; self.do_And(),
    "As" =&gt; self.do_As(),
    "Assert" =&gt; self.do_Assert(),
    "At" =&gt; self.do_At(),
    "Break" =&gt; self.do_Break(),
    "Class" =&gt; self.do_Class(),
    "Colon" =&gt; self.do_Colon(),
    "ColonEqual" =&gt; self.do_ColonEqual(),
    "Comma" =&gt; self.do_Comma(),
    "Comment" =&gt; self.do_Comment(value),
    "Complex" =&gt; self.do_Complex(value),
    "Continue" =&gt; self.do_Continue(),
    "Dedent" =&gt; self.do_Dedent(value),
    "Def" =&gt; self.do_Def(),
    "Del" =&gt; self.do_Del(),
    "Dot" =&gt; self.do_Dot(),
    "DoubleStar" =&gt; self.do_DoubleStar(),
    "Elif" =&gt; self.do_Elif(),
    "Else" =&gt; self.do_Else(),
    "Equal" =&gt; self.do_Equal(),
    "EqEqual" =&gt; self.do_EqEqual(),
    "Except" =&gt; self.do_Except(),
    "Greater" =&gt; self.do_Greater(),
    "GreaterEqual" =&gt; self.do_GreaterEqual(),
    "False" =&gt; self.do_False(),
    "Finally" =&gt; self.do_Finally(),
    "Float" =&gt; self.do_Float(value),
    "For" =&gt; self.do_For(),
    "From" =&gt; self.do_From(),
    "If" =&gt; self.do_If(),
    "In" =&gt; self.do_In(),
    "Import" =&gt; self.do_Import(),
    "Indent" =&gt; self.do_Indent(value),
    "Int" =&gt; self.do_Int(value),
    "Is" =&gt; self.do_Is(),
    "Less" =&gt; self.do_Less(),
    "LessEqual" =&gt; self.do_LessEqual(),
    "Lbrace" =&gt; self.do_Lbrace(),
    "Lpar" =&gt; self.do_Lpar(),
    "Lsqb" =&gt; self.do_Lsqb(),
    "Minus" =&gt; self.do_Minus(),
    "MinusEqual" =&gt; self.do_MinusEqual(),
    "Name" =&gt; self.do_Name(value),
    "Newline" =&gt; self.do_Newline(),
    "None" =&gt; self.do_None(),
    "NonLogicalNewline" =&gt; self.do_NonLogicalNewline(),
    "Not" =&gt; self.do_Not(),
    "NotEqual" =&gt; self.do_NotEqual(),
    "Or" =&gt; self.do_Or(),
    "Pass" =&gt; self.do_Pass(),
    "Percent" =&gt; self.do_Percent(),
    "Plus" =&gt; self.do_Plus(),
    "PlusEqual" =&gt; self.do_PlusEqual(),
    "Raise" =&gt; self.do_Raise(),
    "Rarrow" =&gt; self.do_Rarrow(),
    "Rbrace" =&gt; self.do_Rbrace(),
    "Return" =&gt; self.do_Return(),
    "Rpar" =&gt; self.do_Rpar(),
    "Rsqb" =&gt; self.do_Rsqb(),
    "Star" =&gt; self.do_Star(),
    "String" =&gt; self.do_String(value),
    "True" =&gt; self.do_True(),
    "Try" =&gt; self.do_Try(),
    "While" =&gt; self.do_While(),
    "With" =&gt; self.do_With(),
    "ws" =&gt; self.do_ws(kind, value),
    _ =&gt; println!("No visitor for: {kind}"),
}
</t>
<t tx="ekr.20241002071143.1">// *** Temporary
#[allow(unused_variables)]
fn do_ws(&amp;mut self, kind: &amp;str, value: &amp;str) {
    //! Handle the "ws" pseudo-token.
    //! Put the whitespace only if if ends with backslash-newline.

    // To do.

    // let last_token = self.input_tokens[self.index - 1];
    // let is_newline = kind in ("nl", "newline");
    // if is_newline {
    // self.pending_lws = val;
    // self.pending_ws = "";
    // }
    // else if "\\\n" in val {
    // self.pending_lws = "";
    // self.pending_ws = val;
    // }
    // else {
    // self.pending_ws = val
    // }
}
</t>
<t tx="ekr.20241002113506.1">// Variant names are necessary, but otherwise not used.
#[allow(unused_variables)]
let class_name = match token {
    // Tokens with values...
    Comment(value) =&gt; "Comment",
    Complex { real, imag } =&gt; "Complex",
    Float { value } =&gt; "Float",
    Int { value } =&gt; "Int",
    Name { name } =&gt; "Name",
    Tok::String {
        value,
        kind,
        triple_quoted,
    } =&gt; "String",

    // Common tokens...
    Class =&gt; "Class",
    Dedent =&gt; "Dedent",
    Def =&gt; "Def",
    Indent =&gt; "Indent",
    Newline =&gt; "Newline",
    NonLogicalNewline =&gt; "NonLogicalNewline",

    // All other tokens...
    Amper =&gt; "Amper",
    AmperEqual =&gt; "AmperEqual",
    And =&gt; "And",
    As =&gt; "As",
    Assert =&gt; "Assert",
    Async =&gt; "Async",
    At =&gt; "At",
    AtEqual =&gt; "AtEqual",
    Await =&gt; "Await",
    Break =&gt; "Break",
    Case =&gt; "Case",
    CircumFlex =&gt; "CircumFlex",
    CircumflexEqual =&gt; "CircumflexEqual",
    Colon =&gt; "Colon",
    ColonEqual =&gt; "ColonEqual",
    Comma =&gt; "Comma",
    Continue =&gt; "Continue",
    Del =&gt; "Del",
    Dot =&gt; "Dot",
    DoubleSlash =&gt; "DoubleSlash",
    DoubleSlashEqual =&gt; "DoubleSlashEqual",
    DoubleStar =&gt; "DoubleStar",
    DoubleStarEqual =&gt; "DoubleStarEqual",
    Elif =&gt; "Elif",
    Ellipsis =&gt; "Ellipsis",
    Else =&gt; "Else",
    EndOfFile =&gt; "EndOfFile",
    EqEqual =&gt; "EqEqual",
    Equal =&gt; "Equal",
    Except =&gt; "Except",
    False =&gt; "False",
    Finally =&gt; "Finally",
    For =&gt; "For",
    From =&gt; "From",
    Global =&gt; "Global",
    Greater =&gt; "Greater",
    GreaterEqual =&gt; "GreaterEqual",
    If =&gt; "If",
    Import =&gt; "Import",
    In =&gt; "In",
    Is =&gt; "Is",
    Lambda =&gt; "Lambda",
    Lbrace =&gt; "Lbrace",
    LeftShift =&gt; "LeftShift",
    LeftShiftEqual =&gt; "LeftShiftEqual",
    Less =&gt; "Less",
    LessEqual =&gt; "LessEqual",
    Lpar =&gt; "Lpar",
    Lsqb =&gt; "Lsqb",
    Match =&gt; "Match",
    Minus =&gt; "Minus",
    MinusEqual =&gt; "MinusEqual",
    None =&gt; "None",
    Nonlocal =&gt; "Nonlocal",
    Not =&gt; "Not",
    NotEqual =&gt; "NotEqual",
    Or =&gt; "Or",
    Pass =&gt; "Pass",
    Percent =&gt; "Percent",
    PercentEqual =&gt; "PercentEqual",
    Plus =&gt; "Plus",
    PlusEqual =&gt; "PlusEqual",
    Raise =&gt; "Raise",
    Rarrow =&gt; "Rarrow",
    Rbrace =&gt; "Rbrace",
    Return =&gt; "Return",
    RightShift =&gt; "RightShift",
    RightShiftEqual =&gt; "RightShiftEqual",
    Rpar =&gt; "Rpar",
    Rsqb =&gt; "Rsqb",
    Semi =&gt; "Semi",
    Slash =&gt; "Slash",
    SlashEqual =&gt; "SlashEqual",
    Star =&gt; "Star",
    StarEqual =&gt; "StarEqual",
    StartExpression =&gt; "StartExpression",
    StartInteractive =&gt; "StartInteractive",
    StartModule =&gt; "StartModule",
    Tilde =&gt; "Tilde",
    True =&gt; "True",
    Try =&gt; "Try",
    Type =&gt; "Type",
    Vbar =&gt; "Vbar",
    VbarEqual =&gt; "VbarEqual",
    While =&gt; "While",
    With =&gt; "With",
    Yield =&gt; "Yield",
};
</t>
<t tx="ekr.20241002163554.1">fn string_to_static_str(&amp;self, s: String) -&gt; &amp;'static str {
    Box::leak(s.into_boxed_str())
}

</t>
<t tx="ekr.20241002164044.1">
    // Calculating the class name directly is slower.

    // Furthermore, ':?' lists any fields that the token has.
    let temp_class_name = f!("{token:?}");

    // println!("{temp_class_name}");
    let class_name: &amp;'static str = self.string_to_static_str(temp_class_name);
    self.add_input_token(class_name, tok_value);
</t>
<t tx="ekr.20241003055233.1">    // Don't use static lifetime!  It won't work with multiple files.
    let temp_contents = fs::read_to_string(file_name).expect("Error reading{file_name}");
    // https://stackoverflow.com/questions/23975391/how-to-convert-a-string-into-a-static-str
    let contents: &amp;'static str = self.string_to_static_str(temp_contents);
    let read_time = t1.elapsed().as_nanos();</t>
<t tx="ekr.20241003062509.1">@nosearch</t>
<t tx="ekr.20241003063446.1"></t>
<t tx="ekr.20241003063446.10"></t>
<t tx="ekr.20241003063446.100">fn do_Star(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Star", "*");
}
</t>
<t tx="ekr.20241003063446.101">fn do_StarEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "StarEqual", "*=");
}
</t>
<t tx="ekr.20241003063446.102">fn do_StartExpression(output_list: Vec&lt;String&gt;) {
    // add_output_string(output_list, "StartExpression", "");
}
</t>
<t tx="ekr.20241003063446.103">fn do_StartInteractive(output_list: Vec&lt;String&gt;) {
    // add_output_string(output_list, "StartModule", "");
}
</t>
<t tx="ekr.20241003063446.104">fn do_StartModule(output_list: Vec&lt;String&gt;) {
    // add_output_string(output_list, "StartModule", "");
    println!("do_StartModule");
}
</t>
<t tx="ekr.20241003063446.105">fn do_Tilde(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Tilde", "~");
}
</t>
<t tx="ekr.20241003063446.106">fn do_True(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "True", "True");
}
</t>
<t tx="ekr.20241003063446.107">fn do_Try(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Try", "try");
}
</t>
<t tx="ekr.20241003063446.108">fn do_Type(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Type", "type");
}
</t>
<t tx="ekr.20241003063446.109">fn do_Vbar(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Vbar", "|");
}
</t>
<t tx="ekr.20241003063446.11">// *** Temporary
#[allow(unused_variables)]
fn do_ws(output_list: Vec&lt;String&gt;, kind: &amp;str, value: &amp;str) {
    //! Handle the "ws" pseudo-token.
    //! Put the whitespace only if if ends with backslash-newline.

    // To do.

    // let last_token = self.input_tokens[self.index - 1];
    // let is_newline = kind in ("nl", "newline");
    // if is_newline {
    // self.pending_lws = val;
    // self.pending_ws = "";
    // }
    // else if "\\\n" in val {
    // self.pending_lws = "";
    // self.pending_ws = val;
    // }
    // else {
    // self.pending_ws = val
    // }
}
</t>
<t tx="ekr.20241003063446.110">fn do_VbarEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "VbarEqual", "|=");
}
</t>
<t tx="ekr.20241003063446.111">fn do_While(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "While", "while");
}
</t>
<t tx="ekr.20241003063446.112">fn do_With(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "With", "with");
}
</t>
<t tx="ekr.20241003063446.113">fn do_Yield(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Yield", "yield");
}
</t>
<t tx="ekr.20241003063446.114">fn enabled(&amp;self, arg: &amp;str) -&gt; bool {
    //! Beautifier::enabled: return true if the given command-line argument is enabled.
    //! Example:  x.enabled("--report");
    return self.args.contains(&amp;arg.to_string());
}
</t>
<t tx="ekr.20241003063446.115">fn get_args(&amp;mut self) {
    //! Beautifier::get_args: Set the args and files_list ivars.
    let args: Vec&lt;String&gt; = env::args().collect();
    let valid_args = vec![
        "--all",
        "--beautified",
        "--diff",
        "-h",
        "--help",
        "--report",
        "--write",
    ];
    for (i, arg) in args.iter().enumerate() {
        if i &gt; 0 {
            if valid_args.contains(&amp;arg.as_str()) {
                self.args.push(arg.to_string())
            } else if arg.as_str().starts_with("--") || arg.as_str().starts_with("--") {
                println!("Ignoring invalid arg: {arg}");
            } else {
                println!("File: {arg}");
                self.files_list.push(arg.to_string());
            }
        }
    }
}
</t>
<t tx="ekr.20241003063446.116">fn make_input_list(contents: &amp;str, stats: &amp;Stats) -&gt; Vec&lt;InputTok&gt; {
    // Add InputToks to the input_list for every token given by the RustPython lex.
    let mut n_tokens: u64 = 0;
    let mut n_ws_tokens: u64 = 0;
    let mut prev_start: usize = 0;
    let mut input_list: Vec&lt;InputTok&gt; = Vec::new();

    for token_tuple in lex(&amp;contents, Mode::Module)
        .map(|tok| tok.expect("Failed to lex"))
        .collect::&lt;Vec&lt;_&gt;&gt;()
    {
        use Tok::*;
        n_tokens += 1;
        let (token, range) = token_tuple;
        let tok_value = &amp;contents[range];

        // The gem: create a whitespace pseudo-tokens.
        // This code adds maybe about 1 ms when beautifying leoFrame.py.
        // With the gem: 14.1 - 14.5 ms. Without: 13.1 - 13.7 ms.
        let start_i = usize::from(range.start());
        let end_i = usize::from(range.end());
        if start_i &gt; prev_start {
            let ws = &amp;contents[prev_start..start_i];
            add_input_token(&amp;mut input_list, "ws", ws);
            n_ws_tokens += 1
        }
        prev_start = end_i;

        &lt;&lt; Calculate class_name using match token &gt;&gt;
        add_input_token(&amp;mut input_list, class_name, tok_value);
    }
    // Update counts.
    stats.n_tokens += n_tokens;
    stats.n_ws_tokens += n_ws_tokens;
    return input_list;
}
</t>
<t tx="ekr.20241003063446.117">// Variant names are necessary, but otherwise not used.
#[allow(unused_variables)]
let class_name = match token {
    // Tokens with values...
    Comment(value) =&gt; "Comment",
    Complex { real, imag } =&gt; "Complex",
    Float { value } =&gt; "Float",
    Int { value } =&gt; "Int",
    Name { name } =&gt; "Name",
    Tok::String {
        value,
        kind,
        triple_quoted,
    } =&gt; "String",

    // Common tokens...
    Class =&gt; "Class",
    Dedent =&gt; "Dedent",
    Def =&gt; "Def",
    Indent =&gt; "Indent",
    Newline =&gt; "Newline",
    NonLogicalNewline =&gt; "NonLogicalNewline",

    // All other tokens...
    Amper =&gt; "Amper",
    AmperEqual =&gt; "AmperEqual",
    And =&gt; "And",
    As =&gt; "As",
    Assert =&gt; "Assert",
    Async =&gt; "Async",
    At =&gt; "At",
    AtEqual =&gt; "AtEqual",
    Await =&gt; "Await",
    Break =&gt; "Break",
    Case =&gt; "Case",
    CircumFlex =&gt; "CircumFlex",
    CircumflexEqual =&gt; "CircumflexEqual",
    Colon =&gt; "Colon",
    ColonEqual =&gt; "ColonEqual",
    Comma =&gt; "Comma",
    Continue =&gt; "Continue",
    Del =&gt; "Del",
    Dot =&gt; "Dot",
    DoubleSlash =&gt; "DoubleSlash",
    DoubleSlashEqual =&gt; "DoubleSlashEqual",
    DoubleStar =&gt; "DoubleStar",
    DoubleStarEqual =&gt; "DoubleStarEqual",
    Elif =&gt; "Elif",
    Ellipsis =&gt; "Ellipsis",
    Else =&gt; "Else",
    EndOfFile =&gt; "EndOfFile",
    EqEqual =&gt; "EqEqual",
    Equal =&gt; "Equal",
    Except =&gt; "Except",
    False =&gt; "False",
    Finally =&gt; "Finally",
    For =&gt; "For",
    From =&gt; "From",
    Global =&gt; "Global",
    Greater =&gt; "Greater",
    GreaterEqual =&gt; "GreaterEqual",
    If =&gt; "If",
    Import =&gt; "Import",
    In =&gt; "In",
    Is =&gt; "Is",
    Lambda =&gt; "Lambda",
    Lbrace =&gt; "Lbrace",
    LeftShift =&gt; "LeftShift",
    LeftShiftEqual =&gt; "LeftShiftEqual",
    Less =&gt; "Less",
    LessEqual =&gt; "LessEqual",
    Lpar =&gt; "Lpar",
    Lsqb =&gt; "Lsqb",
    Match =&gt; "Match",
    Minus =&gt; "Minus",
    MinusEqual =&gt; "MinusEqual",
    None =&gt; "None",
    Nonlocal =&gt; "Nonlocal",
    Not =&gt; "Not",
    NotEqual =&gt; "NotEqual",
    Or =&gt; "Or",
    Pass =&gt; "Pass",
    Percent =&gt; "Percent",
    PercentEqual =&gt; "PercentEqual",
    Plus =&gt; "Plus",
    PlusEqual =&gt; "PlusEqual",
    Raise =&gt; "Raise",
    Rarrow =&gt; "Rarrow",
    Rbrace =&gt; "Rbrace",
    Return =&gt; "Return",
    RightShift =&gt; "RightShift",
    RightShiftEqual =&gt; "RightShiftEqual",
    Rpar =&gt; "Rpar",
    Rsqb =&gt; "Rsqb",
    Semi =&gt; "Semi",
    Slash =&gt; "Slash",
    SlashEqual =&gt; "SlashEqual",
    Star =&gt; "Star",
    StarEqual =&gt; "StarEqual",
    StartExpression =&gt; "StartExpression",
    StartInteractive =&gt; "StartInteractive",
    StartModule =&gt; "StartModule",
    Tilde =&gt; "Tilde",
    True =&gt; "True",
    Try =&gt; "Try",
    Type =&gt; "Type",
    Vbar =&gt; "Vbar",
    VbarEqual =&gt; "VbarEqual",
    While =&gt; "While",
    With =&gt; "With",
    Yield =&gt; "Yield",
};
</t>
<t tx="ekr.20241003063446.118">fn show_args(&amp;self) {
    println!("Command-line arguments...");
    for (i, arg) in self.args.iter().enumerate() {
        if i &gt; 0 {
            println!("  {arg}");
        }
    }
    for file_arg in self.files_list.iter() {
        println!("  {file_arg}");
    }
}
</t>
<t tx="ekr.20241003063446.119">fn show_help(&amp;self) {
    //! Beautifier::show_help: print the help messages.
    println!(
        "{}",
        textwrap::dedent(
            "
        Beautify or diff files.

        -h --help:      Print this help message and exit.
        --all:          Beautify all files, even unchanged files.
        --beautified:   Report beautified files individually, even if not written.
        --diff:         Show diffs instead of changing files.
        --report:       Print summary report.
        --write:        Write beautifed files (dry-run mode otherwise).
    "
        )
    );
}
</t>
<t tx="ekr.20241003063446.12"></t>
<t tx="ekr.20241003063446.120">fn show_output_list(&amp;self) {
    println!("\nOutput list...");
    for (i, arg) in self.output_list.iter().enumerate() {
        if i &gt; 0 {
            print!("{:?}", arg);
        }
    }
}
</t>
<t tx="ekr.20241003063446.121">fn string_to_static_str(&amp;self, s: String) -&gt; &amp;'static str {
    Box::leak(s.into_boxed_str())
}

</t>
<t tx="ekr.20241003063446.13">fn do_Comment(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    // print!("{tok_value}");  // Correct.
    // print!("{value} ");  // Wrong!
    add_output_string(output_list, "Comment", tok_value);
}
</t>
<t tx="ekr.20241003063446.14">fn do_Complex(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    add_output_string(output_list, "Complex", tok_value);
}
</t>
<t tx="ekr.20241003063446.15">fn do_Float(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    add_output_string(output_list, "Float", tok_value);
}
</t>
<t tx="ekr.20241003063446.16">fn do_Int(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    add_output_string(output_list, "Int", tok_value);
}
</t>
<t tx="ekr.20241003063446.17">fn do_Name(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    add_output_string(output_list, "Name", tok_value);
}
</t>
<t tx="ekr.20241003063446.18">fn do_String(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    // correct.
    // print!("{tok_value}");

    // incorrect.
    // let quote = if *triple_quoted {"'''"} else {"'"};
    // print!("{:?}:{quote}{value}{quote}", kind);

    add_output_string(output_list, "String", tok_value);
}
</t>
<t tx="ekr.20241003063446.19"></t>
<t tx="ekr.20241003063446.20">fn do_Dedent(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    add_output_string(output_list, "Dedent", tok_value);
}
</t>
<t tx="ekr.20241003063446.21">fn do_Indent(output_list: Vec&lt;String&gt;, tok_value: &amp;str) {
    add_output_string(output_list, "Indent", tok_value);
}
</t>
<t tx="ekr.20241003063446.22">fn do_Newline(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Indent", "\n");
}
</t>
<t tx="ekr.20241003063446.23">fn do_NonLogicalNewline(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Indent", "\n");
}
</t>
<t tx="ekr.20241003063446.24"></t>
<t tx="ekr.20241003063446.25">fn do_Amper(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Amper", "&amp;");
}
</t>
<t tx="ekr.20241003063446.26">fn do_AmperEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "AmperEqual", "&amp;=");
}
</t>
<t tx="ekr.20241003063446.27">fn do_And(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "And", "and");
}
</t>
<t tx="ekr.20241003063446.28">fn do_As(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "As", "as");
}
</t>
<t tx="ekr.20241003063446.29">fn do_Assert(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Assert", "assert");
}
</t>
<t tx="ekr.20241003063446.3">// #[allow(dead_code)]
fn add_input_token(input_list: &amp;mut Vec&lt;InputTok&gt;, kind: &amp;str, value: &amp;str) {
    //! Add one token to the output list.
    input_list.push(InputTok {
        kind: kind.to_string(),
        value: value.to_string(),
    });
}
</t>
<t tx="ekr.20241003063446.30">fn do_Async(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Async", "async");
}
</t>
<t tx="ekr.20241003063446.31">fn do_At(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "At", "@");
}
</t>
<t tx="ekr.20241003063446.32">fn do_AtEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "AtEqual", "@=");
}
</t>
<t tx="ekr.20241003063446.33">fn do_Await(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Await", "await");
}
</t>
<t tx="ekr.20241003063446.34">fn do_Break(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Break", "break");
}
</t>
<t tx="ekr.20241003063446.35">fn do_Case(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Case", "case");
}
</t>
<t tx="ekr.20241003063446.36">fn do_CircumFlex(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "CircumFlex", "^");
}
</t>
<t tx="ekr.20241003063446.37">fn do_CircumflexEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "CircumflexEqual", "^=");
}
</t>
<t tx="ekr.20241003063446.38">fn do_Class(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Class", "class");
}
</t>
<t tx="ekr.20241003063446.39">fn do_Colon(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Colon", ":");
}
</t>
<t tx="ekr.20241003063446.4">#[allow(unused_variables)]
fn add_output_string(mut output_list: Vec&lt;String&gt;, kind: &amp;str, value: &amp;str) {
    //! Add value to the output list.
    //! kind is for debugging.
    if !value.is_empty() {
        output_list.push(value.to_string())
    }
}
</t>
<t tx="ekr.20241003063446.40">fn do_ColonEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "ColonEqual", ":=");
}
</t>
<t tx="ekr.20241003063446.41">fn do_Comma(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Comma", ",");
}
</t>
<t tx="ekr.20241003063446.42">fn do_Continue(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Continue", "continue");
}
</t>
<t tx="ekr.20241003063446.43">fn do_Def(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Def", "def");
}
</t>
<t tx="ekr.20241003063446.44">fn do_Del(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Del", "del");
}
</t>
<t tx="ekr.20241003063446.45">fn do_Dot(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Dot", ".");
}
</t>
<t tx="ekr.20241003063446.46">fn do_DoubleSlash(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "DoubleSlash", "//");
}
</t>
<t tx="ekr.20241003063446.47">fn do_DoubleSlashEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "DoubleSlashEqual", "//=");
}
</t>
<t tx="ekr.20241003063446.48">fn do_DoubleStar(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "DoubleStar", "**");
}
</t>
<t tx="ekr.20241003063446.49">fn do_DoubleStarEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "DoubleStarEqual", "**=");
}
</t>
<t tx="ekr.20241003063446.5">fn beautify(input_list: &amp;Vec&lt;InputTok&gt;) -&gt; String {
    //! Beautify the input_tokens, creating the output_list.
    // &lt; &lt; fn: beautify: init vars &gt;&gt;
    let output_list: Vec&lt;String&gt; = Vec::new();
    if true {
        for input_token in input_list {
            &lt;&lt; LB: beautify: dispatch on input_token.kind &gt;&gt;
        }
    }
    // return ''.join(self.output_list);
    let mut result = String::new();
    for s in output_list {
        result.push_str(&amp;s);
    }
    return result;
}
</t>
<t tx="ekr.20241003063446.50">fn do_Elif(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Elif", "elif");
}
</t>
<t tx="ekr.20241003063446.51">fn do_Ellipsis(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Ellipsis", "...");
}
</t>
<t tx="ekr.20241003063446.52">fn do_Else(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Else", "else");
}
</t>
<t tx="ekr.20241003063446.53">fn do_EndOfFile(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "EndOfFile", "EOF");
}
</t>
<t tx="ekr.20241003063446.54">fn do_EqEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "EqEqual", "==");
}
</t>
<t tx="ekr.20241003063446.55">fn do_Equal(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Equal", "=");
}
</t>
<t tx="ekr.20241003063446.56">fn do_Except(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Except", "except");
}
</t>
<t tx="ekr.20241003063446.57">fn do_False(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "False", "False");
}
</t>
<t tx="ekr.20241003063446.58">fn do_Finally(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Finally", "finally");
}
</t>
<t tx="ekr.20241003063446.59">fn do_For(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "For", "for");
}
</t>
<t tx="ekr.20241003063446.6">// Debugging vars...
line_number = 0; // was None?

// State vars for whitespace.
curly_brackets_level = 0; // Number of unmatched '{' tokens.
paren_level = 0; // Number of unmatched '(' tokens.
square_brackets_stack = Vec::new(); // A stack of bools, for gen_word().
indent_level = 0; // Set only by do_indent and do_dedent.

// Parse state.
decorator_seen = false; // Set by do_name for do_op.
in_arg_list = 0; // &gt; 0 if in an arg list of a def.
in_doc_part = false;

// To do.
// state_stack = Vec::new();  // list[ParseState] = []  # Stack of ParseState objects.

// Leo-related state.
verbatim = false; // True: don't beautify.

// Ivars describing the present input token...
index = 0; // The index within the tokens array of the token being scanned.
lws = String::new(); // Leading whitespace. Required!
</t>
<t tx="ekr.20241003063446.60">fn do_From(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "From", "from");
}
</t>
<t tx="ekr.20241003063446.61">fn do_Global(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Global", "global");
}
</t>
<t tx="ekr.20241003063446.62">fn do_Greater(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Greater", "&gt;");
}
</t>
<t tx="ekr.20241003063446.63">fn do_GreaterEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "GreaterEqual", "&gt;-");
}
</t>
<t tx="ekr.20241003063446.64">fn do_If(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "If", "if");
}
</t>
<t tx="ekr.20241003063446.65">fn do_Import(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Import", "import");
}
</t>
<t tx="ekr.20241003063446.66">fn do_In(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "In", "in");
}
</t>
<t tx="ekr.20241003063446.67">fn do_Is(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Is", "is");
}
</t>
<t tx="ekr.20241003063446.68">fn do_Lambda(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Lambda", "lambda");
}
</t>
<t tx="ekr.20241003063446.69">fn do_Lbrace(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Lbrace", "[");
}
</t>
<t tx="ekr.20241003063446.7">let kind = input_token.kind.as_str();
let value = input_token.kind.as_str();
match kind {
    // Some of these could be replaced by inline code.
    "And" =&gt; do_And(output_list),
    "As" =&gt; do_As(output_list),
    "Assert" =&gt; do_Assert(output_list),
    "At" =&gt; do_At(output_list),
    "Break" =&gt; do_Break(output_list),
    "Class" =&gt; do_Class(output_list),
    "Colon" =&gt; do_Colon(output_list),
    "ColonEqual" =&gt; do_ColonEqual(output_list),
    "Comma" =&gt; do_Comma(output_list),
    "Comment" =&gt; do_Comment(output_list, value),
    "Continue" =&gt; do_Continue(output_list),
    "Dedent" =&gt; do_Dedent(output_list, value),
    "Def" =&gt; do_Def(output_list),
    "Del" =&gt; do_Del(output_list),
    "Dot" =&gt; do_Dot(output_list),
    "DoubleStar" =&gt; do_DoubleStar(output_list),
    "Elif" =&gt; do_Elif(output_list),
    "Else" =&gt; do_Else(output_list),
    "Equal" =&gt; do_Equal(output_list),
    "EqEqual" =&gt; do_EqEqual(output_list),
    "Except" =&gt; do_Except(output_list),
    "Greater" =&gt; do_Greater(output_list),
    "GreaterEqual" =&gt; do_GreaterEqual(output_list),
    "False" =&gt; do_False(output_list),
    "Finally" =&gt; do_Finally(output_list),
    "Float" =&gt; do_Float(output_list, value),
    "For" =&gt; do_For(output_list),
    "From" =&gt; do_From(output_list),
    "If" =&gt; do_If(output_list),
    "In" =&gt; do_In(output_list),
    "Import" =&gt; do_Import(output_list),
    "Indent" =&gt; do_Indent(output_list, value),
    "Int" =&gt; do_Int(output_list, value),
    "Is" =&gt; do_Is(output_list),
    "Less" =&gt; do_Less(output_list),
    "LessEqual" =&gt; do_LessEqual(output_list),
    "Lbrace" =&gt; do_Lbrace(output_list),
    "Lpar" =&gt; do_Lpar(output_list),
    "Lsqb" =&gt; do_Lsqb(output_list),
    "Minus" =&gt; do_Minus(output_list),
    "MinusEqual" =&gt; do_MinusEqual(output_list),
    "Name" =&gt; do_Name(output_list, value),
    "Newline" =&gt; do_Newline(output_list),
    "None" =&gt; do_None(output_list),
    "NonLogicalNewline" =&gt; do_NonLogicalNewline(output_list),
    "Not" =&gt; do_Not(output_list),
    "NotEqual" =&gt; do_NotEqual(output_list),
    "Or" =&gt; do_Or(output_list),
    "Pass" =&gt; do_Pass(output_list),
    "Percent" =&gt; do_Percent(output_list),
    "Plus" =&gt; do_Plus(output_list),
    "PlusEqual" =&gt; do_PlusEqual(output_list),
    "Raise" =&gt; do_Raise(output_list),
    "Rarrow" =&gt; do_Rarrow(output_list),
    "Rbrace" =&gt; do_Rbrace(output_list),
    "Return" =&gt; do_Return(output_list),
    "Rpar" =&gt; do_Rpar(output_list),
    "Rsqb" =&gt; do_Rsqb(output_list),
    "Star" =&gt; do_Star(output_list),
    "String" =&gt; do_String(output_list, value),
    "True" =&gt; do_True(output_list),
    "Try" =&gt; do_Try(output_list),
    "While" =&gt; do_While(output_list),
    "With" =&gt; do_With(output_list),
    "ws" =&gt; do_ws(output_list, kind, value),
    _ =&gt; println!("No visitor for: {kind}"),
}
</t>
<t tx="ekr.20241003063446.70">fn do_LeftShift(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "LeftShift", "&lt;&lt;");
}
</t>
<t tx="ekr.20241003063446.71">fn do_LeftShiftEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "LeftShiftEqual", "&lt;&lt;=");
}
</t>
<t tx="ekr.20241003063446.72">fn do_Less(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Less", "&lt;");
}
</t>
<t tx="ekr.20241003063446.73">fn do_LessEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "LessEqual", "&lt;=");
}
</t>
<t tx="ekr.20241003063446.74">fn do_Lpar(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Lpar", "(");
}
</t>
<t tx="ekr.20241003063446.75">fn do_Lsqb(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Lsqb", "[");
}
</t>
<t tx="ekr.20241003063446.76">fn do_Match(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Match", "match");
}
</t>
<t tx="ekr.20241003063446.77">fn do_Minus(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Minus", "-");
}
</t>
<t tx="ekr.20241003063446.78">fn do_MinusEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "MinusEqual", "-=");
}
</t>
<t tx="ekr.20241003063446.79">fn do_None(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "None", "None");
}
</t>
<t tx="ekr.20241003063446.8">pub fn beautify_all_files(files_list: Vec&lt;String&gt;, stats: &amp;Stats) {
    // for file_name in self.files_list.clone() {
    for file_name in files_list {
        beautify_one_file(&amp;file_name, &amp;stats);
    }
}

</t>
<t tx="ekr.20241003063446.80">fn do_Nonlocal(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Nonlocal", "nonlocal");
}
</t>
<t tx="ekr.20241003063446.81">fn do_Not(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Not", "not");
}
</t>
<t tx="ekr.20241003063446.82">fn do_NotEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "NotEqual", "!=");
}
</t>
<t tx="ekr.20241003063446.83">fn do_Or(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Or", "or");
}
</t>
<t tx="ekr.20241003063446.84">fn do_Pass(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Pass", "pass");
}
</t>
<t tx="ekr.20241003063446.85">fn do_Percent(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Percent", "%");
}
</t>
<t tx="ekr.20241003063446.86">fn do_PercentEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "PercentEqual", "%=");
}
</t>
<t tx="ekr.20241003063446.87">fn do_Plus(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Plus", "+");
}
</t>
<t tx="ekr.20241003063446.88">fn do_PlusEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "PlusEqual", "+=");
}
</t>
<t tx="ekr.20241003063446.89">fn do_Raise(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Raise", "raise");
}
</t>
<t tx="ekr.20241003063446.9">fn beautify_one_file(file_name: &amp;str, stats: &amp;Stats) {
    stats.n_files += 1;
    if true {
        // Testing only: print the short file name.
        let file_path = path::Path::new(file_name);
        let os_str = file_path.file_name().unwrap(); // &amp;OsStr
        let short_file_name = os_str.to_str().unwrap();
        println!("{short_file_name}");
    }
    // Read the file into contents (a String).
    let t1 = std::time::Instant::now();
    let contents = fs::read_to_string(file_name).expect("Error reading{file_name}");
    stats.read_time += t1.elapsed().as_nanos();
    // Make the list of input tokens.
    let t2 = std::time::Instant::now();
    let input_list: Vec&lt;InputTok&gt; = make_input_list(&amp;contents, &amp;stats);
    stats.make_tokens_time += t2.elapsed().as_nanos();
    // Beautify.
    let t3 = std::time::Instant::now();
    let results: String = beautify(&amp;input_list);
    let n =results.len();
    println!("len(results): {n}");
    stats.beautify_time += t3.elapsed().as_nanos();
}
</t>
<t tx="ekr.20241003063446.90">fn do_Rarrow(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Rarrow", "-&gt;");
}
</t>
<t tx="ekr.20241003063446.91">fn do_Rbrace(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Rbrace", "]");
}
</t>
<t tx="ekr.20241003063446.92">fn do_Return(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Return", "return");
}
</t>
<t tx="ekr.20241003063446.93">fn do_RightShift(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "RightShift", "&gt;&gt;");
}
</t>
<t tx="ekr.20241003063446.94">fn do_RightShiftEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "RightShiftEqual", "&gt;&gt;=");
}
</t>
<t tx="ekr.20241003063446.95">fn do_Rpar(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Rpar", ")");
}
</t>
<t tx="ekr.20241003063446.96">fn do_Rsqb(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Rsqb", "]");
}
</t>
<t tx="ekr.20241003063446.97">fn do_Semi(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Semi", ";");
}
</t>
<t tx="ekr.20241003063446.98">fn do_Slash(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "Slash", "/");
}
</t>
<t tx="ekr.20241003063446.99">fn do_SlashEqual(output_list: Vec&lt;String&gt;) {
    add_output_string(output_list, "SlashEqual", "/=");
}
</t>
<t tx="ekr.20241003064425.1">#[derive(Debug)]
pub struct Beautifier {
    // Set in LB:beautify_one_file...
    args: Vec&lt;String&gt;,
    files_list: Vec&lt;String&gt;,
    input_list: Vec&lt;InputTok&gt;,
    output_list: Vec&lt;String&gt;,
    stats: Stats,
    // Set in LB:beautify...
    // Debugging
    line_number: i32, // Use -1 instead of None?
    // State vars for whitespace.
    curly_brackets_level: i32,
    indent_level: i32,
    paren_level: i32,
    square_brackets_stack: Vec&lt;bool&gt;,
    // Parse state.
    decorator_seen: bool, // Set by do_name for do_op.
    in_arg_list: i32,     // &gt; 0 if in an arg list of a def.
    in_doc_part: bool,
    // To do
    // state_stack = Vec&lt;ParseState&gt;,  // list[ParseState] = []  # Stack of ParseState objects.
    // Leo-related state.
    verbatim: bool,
    // Ivars describing the present input token.
    index: u32,
    lws: String,
}

///// Temporary.
#[allow(dead_code)]
#[allow(non_snake_case)]
impl Beautifier {
    @others
}
</t>
<t tx="ekr.20241003064504.1"></t>
<t tx="ekr.20241003084853.1">@nosearch</t>
<t tx="ekr.20241003084902.1">pub fn entry() {
    // Main line of beautifier.
    //** let mut x = Beautifier::new();
   
    // testing.
    println!("");
    let mut stats = Stats {
        n_files: 0, n_tokens: 0, n_ws_tokens: 0,
        beautify_time: 0, make_tokens_time: 0, read_time: 0, write_time: 0,
    };

    for file_path in [
        "C:\\Repos\\leo-editor\\leo\\core\\leoAst.py",
        // "C:\\Repos\\leo-editor\\leo\\core\\leoTokens.py",
        // "C:\\Repos\\leo-editor\\leo\\core\\leoApp.py"
    ] {
        beautify_one_file(&amp;file_path, &amp;stats);
    }
    stats.report();
        
    //*** Not yet.
        // } else {
            // if x.enabled("--help") || x.enabled("-h") {
                // x.show_help();
                // return;
            // }
            // x.show_args();
            // x.beautify_all_files();
        // }
}
</t>
<t tx="ekr.20241004073317.1"></t>
<t tx="ekr.20241004084640.1">@nosearch</t>
<t tx="ekr.20241004093044.1">impl fmt::Debug for InputTok {
    fn fmt(&amp;self, f: &amp;mut fmt::Formatter&lt;'_&gt;) -&gt; fmt::Result {
        let kind_s = format!("{:?}", self.kind);
        let mut value = self.value.to_string();
        if true {
            return write!(f, "{value} ");
        } else {
            // Debug format.
            value.truncate(60);
            // repr format is not useful.
            // let value_s = format!("{:?}", value);
            let value_s = format!("{}", value);
            return write!(f, "InputTok: {kind_s:&gt;10}: {value_s}");
        }
    }
}</t>
<t tx="ekr.20241004095735.1">fn annotate_tokens(&amp;mut self, input_list: &amp;Vec&lt;InputTok&gt;) -&gt; Vec::&lt;AnnotatedInputTok&gt; {
    //! Do the prepass, returning tokens annotated with context.
    
    // *** Not yet: Instantiate the Annotator and call Annotator.pre_pass.
    // let annotator = Annotator::new(input_list);
    // annotator.pre_scan(input_list);

    let mut result = Vec::new();
    for token in input_list {
        let context = Vec::new();
        let annotated_tok = AnnotatedInputTok::new(context, &amp;token.kind, &amp;token.value);
        result.push(annotated_tok)
    }
    return result;
}
</t>
<t tx="ekr.20241004095931.1">#[derive(Clone, Debug)]
struct AnnotatedInputTok {
    context: Vec::&lt;String&gt;,
    kind: String,
    value: String,
}

impl AnnotatedInputTok {
    fn new(context: Vec&lt;String&gt;, kind: &amp;str, value: &amp;str) -&gt; AnnotatedInputTok {
        AnnotatedInputTok {
            context: context,
            kind: kind.to_string(),
            value: value.to_string(),
        }
    }
}
</t>
<t tx="ekr.20241004110721.1">struct Annotator&lt;'a&gt; {
    // The present input token...
    input_tokens: Vec&lt;InputTok&lt;'a&gt;&gt;,
    insignificant_tokens: [String; 6],
    index: u32,  // The index within the tokens array of the token being scanned.
    lws: String,  // Leading whitespace. Required!
    // For whitespace.
    curly_brackets_level: u32,  // Number of unmatched '{' tokens.
    paren_level: u32,  // Number of unmatched '(' tokens.
    square_brackets_stack: Vec&lt;bool&gt;,  // A stack of bools, for     gen_word().
    indent_level: u32,  // Set only by do_indent and do_dedent.
    // Parse state.
    decorator_seen: bool,  // Set by do_name for do_op.
    in_arg_list: u32,  // &gt; 0 if in an arg list of a def.
    in_doc_part: bool,
    state_stack: Vec&lt;ParseState&gt;,  // Stack of ParseState objects.
    verbatim: bool,  // True: don't beautify.
}

impl Annotator&lt;'_&gt; {
    @others
}
</t>
<t tx="ekr.20241004112826.1">struct ParseState {
    &lt;&lt; docstring: ParseState &gt;&gt;
    kind: String,
    value: String,
}
</t>
<t tx="ekr.20241004113118.1">@language rest
@doc

A class representing items in the parse state stack.

The present states:

'file-start': Ensures the stack stack is never empty.

'decorator': The last '@' was a decorator.

    do_op():    push_state('decorator')
    do_name():  pops the stack if state.kind == 'decorator'.

'indent': The indentation level for 'class' and 'def' names.

    do_name():      push_state('indent', self.level)
    do_dendent():   pops the stack once or
                    twice if state.value == self.level.

</t>
<t tx="ekr.20241004153742.1">fn new(input_tokens: Vec&lt;InputTok&gt;) -&gt; Annotator {
    Annotator {
        curly_brackets_level: 0,
        decorator_seen: false,
        in_arg_list: 0,  // &gt; 0 if in an arg list of a def.
        in_doc_part: false,
        indent_level: 0,
        index: 0,
        input_tokens: input_tokens,
        insignificant_tokens: [
            "comment".to_string(), "dedent".to_string(), "indent".to_string(),
            "newline".to_string(), "nl".to_string(), "ws".to_string(),
        ],
        lws: String::new(),
        paren_level: 0,
        state_stack: Vec::new(),
        square_brackets_stack: Vec::new(),
        verbatim: false, 
    }
}
</t>
<t tx="ekr.20241004153802.1">fn pre_scan(&amp;mut self) {
    //! Scan the entire file in one iterative pass, adding context to a few
    //! kinds of tokens as follows:
    //!
    //! Token   Possible Contexts (or None)
    //! =====   ===========================
    //! ":"     "annotation", "dict", "complex-slice", "simple-slice"
    //! "="     "annotation", "initializer"
    //! "*"     "arg"
    //! "**"    "arg"
    //! "."     "import"

    // The main loop.
    let mut in_import = false;
    // Avoid Option complications by creating a dummy token and scan state.
    let dummy_token = InputTok::new("dummy", "");
    let dummy_state = ScanState::new("dummy", &amp;dummy_token);
    let mut scan_stack: Vec&lt;ScanState&gt; = Vec::new();
    scan_stack.push(dummy_state);
    let mut prev_token = InputTok::new("dummy", "");
    let mut i = 0;
    for token in &amp;self.input_tokens {
        let (kind, value) = (token.kind, token.value);
        if kind == "newline" {
            &lt;&lt; pre-scan newline tokens &gt;&gt;
        }
        else if kind == "op" {
            &lt;&lt; pre-scan op tokens &gt;&gt;
        }
        else if kind == "name" {
            &lt;&lt; pre-scan name tokens &gt;&gt;
        }
        // Remember the previous significant token.
        if !self.insignificant_tokens.contains(&amp;kind.to_string()) { 
            prev_token = token.clone();
        }
        i += 1;
    }
    // Sanity check.
    if scan_stack.len() &gt; 0 {
        println!("pre_scan: non-empty scan_stack");
    }
}
</t>
<t tx="ekr.20241004154345.2">// "import" and "from x import" statements may span lines.
// "ws" tokens represent continued lines like this:   ws: " \\\n    "
if in_import &amp;&amp; scan_stack.len() == 0 {
    in_import = false;
}
</t>
<t tx="ekr.20241004154345.3">// top_state: Optional[fScanState] = scan_stack[-1] if scan_stack else None
// The scan_stack always contains at least a dummy state.
let top_state = &amp;mut scan_stack[scan_stack.len() - 1].clone();

// Handle "[" and "]".
if value == "[" {
    scan_stack.push(ScanState::new("slice", &amp;token));
}
else if  value == "]" {
    assert!(top_state.kind == "slice");
    self.finish_slice(i, top_state);
    scan_stack.pop();
}

// Handle "{" and "}".
if value == "{" {
    scan_stack.push(ScanState::new("dict", &amp;token));
}
else if value == "}" {
    assert!(top_state.kind == "dict");
    self.finish_dict(i, top_state);
    scan_stack.pop();
}

// Handle "(" and ")"
else if value == "(" {
    if self.is_python_keyword(&amp;prev_token) || prev_token.kind != "name" {
        scan_stack.push(ScanState::new("(", &amp;token));
    }
    else {
        scan_stack.push(ScanState::new("arg", &amp;token));
    }
}
else if value == ")" {
    assert!(["arg", "("].contains(&amp;top_state.kind));
    if top_state.kind == "arg" {
        self.finish_arg(i, top_state);
    }
    scan_stack.pop();
}

// Handle interior tokens in "arg" and "slice" states.
if top_state.kind != "dummy" {
    if value == ":" &amp;&amp; ["dict", "slice"].contains(&amp;top_state.kind) {
        top_state.indices.push(i);
    }
    else if top_state.kind == "arg" &amp;&amp; ["**", "*", "=", ":", ","].contains(&amp;value) {
        top_state.indices.push(i);
    }
}

// Handle "." and "(" tokens inside "import" and "from" statements.
if in_import &amp;&amp; ["(", "."].contains(&amp;value) {
    self.set_context(i, "import");
}
</t>
<t tx="ekr.20241004154345.4">let prev_is_yield = prev_token.kind == "name" &amp;&amp; prev_token.value == "yield";
// if ["from", "import"].contains(value) &amp;&amp; !prev_is_yield {
if !prev_is_yield &amp;&amp; (value == "from" || value == "import") {
    // "import" and "from x import" statements should be at the outer level.
    assert!(scan_stack.len() == 1 &amp;&amp; scan_stack[0].kind == "dummy");
    in_import = true;
}
</t>
<t tx="ekr.20241004154345.5">fn finish_arg(&amp;self, end: usize, state: &amp;ScanState) {
    //! Set context for all ":" when scanning from "(" to ")".

    // Sanity checks.
    if state.kind == "dummy" {
        return;
    }
    assert!(state.kind == "arg");
    assert!(state.token.value == "(");
    let indices = &amp;state.indices;
    if indices.len() == 0 {
        return;
    }

    // *** let mut i1 = token.index;
    let i1 = 0;  // *** add mut later.
    // assert i1 &lt; end, (i1, end)

    // Compute the context for each *separate* "=" token.
    let mut equal_context = "initializer";
    for i in indices {
        let token = &amp;self.input_tokens[*i];
        assert!(token.kind == "op");
        if token.value == "," {
            equal_context = "initializer";
        }
        else if token.value == ":" {
            equal_context = "annotation";
        }
        else if token.value == "=" {
            self.set_context(*i, equal_context);
            equal_context = "initializer";
        }
    }
    // Set the context of all outer-level ":", "*", and "**" tokens.
    let mut prev_token = &amp;InputTok::new("dummy", "");
    for i in i1..end {
        let token = &amp;self.input_tokens[i];
        if !self.insignificant_tokens.contains(&amp;token.kind.to_string()) {
            if token.kind == "op" {
                // if ["*", "**"].contains(token.value) {
                if token.value == "*" || token.value == "**" {
                    if self.is_unary_op_with_prev(&amp;prev_token, &amp;token) {
                        self.set_context(i, "arg");
                    }
                }
                else if token.value == "=" {
                    // The code above has set the context.
                    // assert token.context in ("initializer", "annotation"), (i, repr(token.context))
                }
                else if token.value == ":" {
                    self.set_context(i, "annotation")
                }
            }
            prev_token = token;
        }
    }
}
</t>
<t tx="ekr.20241004154345.6">fn finish_slice(&amp;self, end: usize, state: &amp;ScanState) {
    //! Set context for all ":" when scanning from "[" to "]".

    // Sanity checks.
    assert!(state.kind == "slice");
    
    let token = state.token;
    assert!(token.value == "[");
    
    let colons = &amp;state.indices;
    
    // *** let mut i1 = token.index;
    let i1 = 0;
    // assert i1 &lt; end, (i1, end)

    // Do nothing if there are no ":" tokens in the slice.
    if colons.len() == 0 {
        return;
    }

    // Compute final context by scanning the tokens.
    let mut final_context = "simple-slice";
    let mut inter_colon_tokens = 0;
    let mut prev: &amp;InputTok = &amp;token;
    for i in i1 + 1..end - 1 {
        let token = &amp;self.input_tokens[i];
        let (kind, value) = (token.kind, token.value);
        if !self.insignificant_tokens.contains(&amp;kind.to_string()) {
            if kind == "op" {
                if *value == *"." {
                    // Ignore "." tokens and any preceding "name" token.
                    if prev.kind == "name" {
                        inter_colon_tokens -= 1;
                    }
                }
                else if *value == *":" {
                    inter_colon_tokens = 0;
                }
                else if *value == *"-" || *value == *"+" {
                    // Ignore unary "-" or "+" tokens.
                    if !self.is_unary_op_with_prev(&amp;prev, &amp;token) {
                        inter_colon_tokens += 1;
                        if inter_colon_tokens &gt; 1 {
                            final_context = "complex-slice";
                            break;
                        }
                    }
                }
                else if *value == *"~" {
                    // "~" is always a unary op.
                }
                else {
                    // All other ops contribute.
                    inter_colon_tokens += 1;
                    if inter_colon_tokens &gt; 1 {
                        final_context = "complex-slice";
                        break;
                    }
                }
            }
            else {
                inter_colon_tokens += 1;
                if inter_colon_tokens &gt; 1 {
                    final_context = "complex-slice";
                    break;
                }
            }
            prev = &amp;token;
        }
    }
    // Set the context of all outer-level ":" tokens.
    for i in colons {
        self.set_context(*i, final_context);
    }    
}
</t>
<t tx="ekr.20241004154345.7">// ***
#[allow(unused_variables)]
fn finish_dict(&amp;self, end: usize, state: &amp;ScanState) {
    //! Set context for all ":" when scanning from "{" to "}"
    //! 
    //! Strictly speaking, setting this context is unnecessary because
    //! Annotator.gen_colon generates the same code regardless of this context.
    //! 
    //! In other words, this method can be a do-nothing!

    // Sanity checks.
    if state.kind == "Dummy" {
        return;
    }
    assert!(state.kind == "dict");

    let token = state.token;
    assert!(token.value == "{");
    
    
    // *** Rewrite
        // let i1 = token.index;
        // assert i1 &lt; end, (i1, end)

    // Set the context for all ":" tokens.
    let indices = &amp;state.indices;
    for i in indices {
        self.set_context(*i, "dict");
    }
}
</t>
<t tx="ekr.20241004163018.1">fn set_context(&amp;self, _i: usize, _context: &amp;str) {  // *** temp.
    //! Set self.input_tokens[i].context, but only if it does not already exist!
    //! See the docstring for pre_scan for details.

    // *** Rewrite.

    // let trace = false;  // Do not delete the trace below.
    // let valid_contexts = [
        // "annotation", "arg", "complex-slice", "simple-slice",
        // "dict", "import", "initializer",
    // ];
    // if !valid_contexts.contain(context) {
        // // self.oops(f"Unexpected context! {context!r}")
        // println!("Unexpected context! {context:?}");
    // }
    // let token = self.input_tokens[i];
    // if trace {  // Do not delete.
        // let token_kind = token.kind;
        // let token_val = token.show_val(12);
        // let token_s = f!("&lt;{token_kind}: {token_val}&gt;");
        // let ignore_s = if token.context { "Ignore" } else { "      "};
        // println!("{i:3} {ignore_s} token: {token_s} context: {context}");
    // }
    // *** Rewrite
    // if token.context.len() == 0 {  // **
        // token.context.push(context);
    // }
}
</t>
<t tx="ekr.20241004165555.1">#[derive(Clone, Debug)]
struct ScanState&lt;'a&gt; {
    // A class representing tbo.pre_scan's scanning state.
    // Valid (kind, value) pairs:
    // kind  Value
    // ====  =====
    // "args" Not used
    // "from" Not used
    // "import" Not used
    // "slice" list of colon indices
    // "dict" list of colon indices

    kind: &amp;'a str,
    token: &amp;'a InputTok&lt;'a&gt;,
    indices: Vec&lt;usize&gt;,  // Empty for most tokens.
}

impl &lt;'a&gt; ScanState&lt;'_&gt; {
    fn new(kind: &amp;'a str, token: &amp;'a InputTok) -&gt; ScanState&lt;'a&gt; {
        ScanState {
            kind: kind,
            token: token,
            indices: Vec::new(),
        }
    }
}
</t>
<t tx="ekr.20241005031511.1">class InputToken:  # leoTokens.py.
    """A class representing a TBO input token."""

    __slots__ = (
        'context',
        'index',
        'kind',
        'line',
        'line_number',
        'value',
    )

    def __init__(
        self, kind: str, value: str, index: int, line: str, line_number: int,
    ) -&gt; None:
        self.context: Optional[str] = None
        self.index = index
        self.kind = kind
        self.line = line  # The entire line containing the token.
        self.line_number = line_number
        self.value = value

    def __repr__(self) -&gt; str:  # pragma: no cover
        s = f"{self.index:&lt;5} {self.kind:&gt;8}"
        return f"Token {s}: {self.show_val(20):22}"

    def __str__(self) -&gt; str:  # pragma: no cover
        s = f"{self.index:&lt;5} {self.kind:&gt;8}"
        return f"Token {s}: {self.show_val(20):22}"

    def to_string(self) -&gt; str:
        """Return the contribution of the token to the source file."""
        return self.value if isinstance(self.value, str) else ''

    @others
</t>
<t tx="ekr.20241005031511.2">def brief_dump(self) -&gt; str:  # pragma: no cover
    """Dump a token."""
    token_s = f"{self.kind:&gt;10} : {self.show_val(10):12}"
    return f"&lt;line: {self.line_number} index: {self.index:3} {token_s}&gt;"

</t>
<t tx="ekr.20241005031511.3">def dump(self) -&gt; str:  # pragma: no cover
    """Dump a token and related links."""
    return (
        f"{self.line_number:4} "
        f"{self.index:&gt;5} {self.kind:&gt;15} "
        f"{self.show_val(100)}"
    )
</t>
<t tx="ekr.20241005031511.4">def dump_header(self) -&gt; None:  # pragma: no cover
    """Print the header for token.dump"""
    print(
        f"\n"
        f"         node    {'':10} token {'':10}   token\n"
        f"line index class {'':10} index {'':10} kind value\n"
        f"==== ===== ===== {'':10} ===== {'':10} ==== =====\n")
</t>
<t tx="ekr.20241005031511.5">def error_dump(self) -&gt; str:  # pragma: no cover
    """Dump a token for error message."""
    return f"index: {self.index:&lt;3} {self.kind:&gt;12} {self.show_val(20):&lt;20}"
</t>
<t tx="ekr.20241005031511.6">def show_val(self, truncate_n: int = 8) -&gt; str:  # pragma: no cover
    """Return the token.value field."""
    if self.kind in ('dedent', 'indent', 'newline', 'ws'):
        # val = str(len(self.value))
        val = repr(self.value)
    elif self.kind == 'string' or self.kind.startswith('fstring'):
        # repr would be confusing.
        val = g.truncate(self.value, truncate_n)
    else:
        val = g.truncate(repr(self.value), truncate_n)
    return val
</t>
<t tx="ekr.20241005091217.1">// def is_python_keyword(self, token: Optional[InputToken]) -&gt; bool:
    // """Return True if token is a 'name' token referring to a Python keyword."""
    // if not token or token.kind != 'name':
        // return False
    // return keyword.iskeyword(token.value) or keyword.issoftkeyword(token.value)
    
// Keywords:
// False      await      else       import     pass
// None       break      except     in         raise
// True       class      finally    is         return
// and        continue   for        lambda     try
// as         def        from       nonlocal   while
// assert     del        global     not        with
// async      elif       if         or         yield

// Soft keywords:
// match, case, type and _

fn is_python_keyword(&amp;self, token: &amp;InputTok) -&gt; bool {  // *** Temp.
    //! Return True if token is a 'name' token referring to a Python keyword.
    if token.kind != "name" {
        return false;
    }
    // let word = &amp;token.value;  // &amp;String
    return false;  // ***
}
</t>
<t tx="ekr.20241005092549.1">// def is_unary_op_with_prev(self, prev: Optional[InputToken], token: InputToken) -&gt; bool:
    // """
    // Return True if token is a unary op in the context of prev, the previous
    // significant token.
    // """
    // if token.value == '~':  # pragma: no cover
        // return True
    // if prev is None:
        // return True  # pragma: no cover
    // assert token.value in '**-+', repr(token.value)
    // if prev.kind in ('number', 'string'):
        // return_val = False
    // elif prev.kind == 'op' and prev.value in ')]':
         // # An unnecessary test?
        // return_val = False  # pragma: no cover
    // elif prev.kind == 'op' and prev.value in '{([:,':
        // return_val = True
    // elif prev.kind != 'name':
        // # An unnecessary test?
        // return_val = True  # pragma: no cover
    // else:
        // # prev is a'name' token.
        // return self.is_python_keyword(token)
    // return return_val

fn is_unary_op_with_prev(&amp;self, _prev_token: &amp;InputTok, _token: &amp;InputTok) -&gt; bool {  // *** Temp. _
    return false;  // ***
}
</t>
<t tx="ekr.20241006034023.1">@language rest
@wrap

Old: input_tokens: Vec&lt;InputTok&lt;'a&gt;&gt;,
New: input_tokens: &amp;Vec&lt;InputTok&lt;'a&gt;&gt;,  *** need lifetime?
- Instantiate Annotator.
- Call Annotator.pre_scan.</t>
</tnodes>
</leo_file>
